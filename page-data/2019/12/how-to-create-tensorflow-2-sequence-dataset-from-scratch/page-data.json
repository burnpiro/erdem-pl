{"componentChunkName":"component---src-templates-post-template-js","path":"/2019/12/how-to-create-tensorflow-2-sequence-dataset-from-scratch","webpackCompilationHash":"66893a366a98cf7c4395","result":{"data":{"markdownRemark":{"fields":{"slug":"/2019/12/how-to-create-tensorflow-2-sequence-dataset-from-scratch","tagSlugs":["/tag/tensorflow/","/tag/machine-learning/","/tag/ai/","/tag/data/"],"readTime":{"text":"41 min read","minutes":40.233333333333334}},"frontmatter":{"description":"How to create your own Dataset for Tensorflow model training by extending Sequence class?","tags":["Tensorflow","Machine Learning","AI","Data"],"date":"2019-12-28","title":"How to create Tensorflow 2 Sequence Dataset from scratch"},"html":"<figure class=\"image\">\n  <a class=\"gatsby-resp-image-link\" href=\"/static/11eabe31675d3e4b757b0582e281ab7c/5415d/dataset.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 960px;\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 26.789168278529978%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABPElEQVQY0wExAc7+AD9kKUpnMFVyOEtlOUxyMVx7OFFxOmB4QkppNjdTJ2BdU18oE3VWS3KUUG57TXFLQzkUAGBhV4KSZqKnqgBFWi5QaDdRdjNCUStTg0FyjFJZdD5ZgT5DXytHPSp4g1pDNRxdXVNidUZ7i1pSWksmIwxGUUlXckDLnpcAdHJaUmY6W3I8eIBbhItqWmRCV2A+JC0pZFlHY0s3ZmFXAgoURD5BWVRRg4R/RDo/BQAATElQXVRW3J6jAF1MRM3CuzUzKX5cUIqHW01aOisvIDMuJVVEPE9ERGdeY2ZGO2VVVYClk32iiVpLT0c9PGdtaZSffa65kwCLhYKfnJYFBAIYEBAnLSRMS0A6MDEbGhocGhVTVFlkbXonGBo8OSqIhnWagWc+OiwHFRkwOjhKVkdIVUYez2Ls7+6n9gAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n    <img class=\"gatsby-resp-image-image\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\" alt=\"Dataset Example\" title src=\"/static/11eabe31675d3e4b757b0582e281ab7c/f570d/dataset.png\" srcset=\"/static/11eabe31675d3e4b757b0582e281ab7c/0783d/dataset.png 240w,\n/static/11eabe31675d3e4b757b0582e281ab7c/782f4/dataset.png 480w,\n/static/11eabe31675d3e4b757b0582e281ab7c/f570d/dataset.png 960w,\n/static/11eabe31675d3e4b757b0582e281ab7c/8d0ff/dataset.png 1440w,\n/static/11eabe31675d3e4b757b0582e281ab7c/a987b/dataset.png 1920w,\n/static/11eabe31675d3e4b757b0582e281ab7c/5415d/dataset.png 2068w\" sizes=\"(max-width: 960px) 100vw, 960px\">\n  </span>\n  </a>\n  <figcaption>Image source: https://swinghu.github.io/assets/face-detection-recognition/From_Facial_Parts_Responses_to_Face_Detection_A_Deep_Learning_Approach_index.png</figcaption>\n</figure>\n<h2 id=\"the-problem\"><a href=\"#the-problem\" aria-label=\"the problem permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The problem</h2>\n<p>Modern Machine Learning solutions require a huge amount of data, that’s definitely the case when working with image recognition/object detection. Because of that, we need to create more and more complex datasets to teach our models. At this moment we cannot store the whole thing in the memory (sometimes even hard drive has a problem), quite often a description of that dataset is not directly readable by Tensorflow’s <strong>Dataset</strong>. That’s why we need to create a modern solution to handle and preprocess an enormous amount of data in easy to understand way using Sequences.</p>\n<blockquote>\n<p><strong>TLDR</strong>:</p>\n<p>Here is a code: <a href=\"https://gist.github.com/burnpiro/c3835a1f914545f2034f4190b1e83153\">https://gist.github.com/burnpiro/c3835a1f914545f2034f4190b1e83153</a></p>\n<p>Use Sequences to make datasets maintainable and fast.</p>\n</blockquote>\n<h2 id=\"what-is-the-sequence\"><a href=\"#what-is-the-sequence\" aria-label=\"what is the sequence permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What is the Sequence?</h2>\n<p>According to documentation, Sequence is:</p>\n<blockquote>\n<p><strong>Base object for fitting to a sequence of data, such as a dataset.</strong></p>\n</blockquote>\n<p>Sequence object is created using <a href=\"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/utils/data_utils.py#L331-L406\"><strong>Sequence Class</strong></a>. The best thing about it is that we can extend it. Every Sequence has to implement 3 methods:</p>\n<ul>\n<li><code class=\"language-text\">__getitem__</code> - used to extract item from dataset</li>\n<li><code class=\"language-text\">__len__</code> - returns the length of our dataset</li>\n<li><code class=\"language-text\">__init__</code> - initializing our dataset (this one is not required but we need some kind of initialization)</li>\n</ul>\n<p>Sequence allows us to create complex datasets and even modify them at the end of each epoch by implementing <code class=\"language-text\">on_epoch_end</code>. We’re going to focus only on those 3 methods but if you can you can play with <code class=\"language-text\">on_epoch_end</code>.</p>\n<h2 id=\"our-test-dataset\"><a href=\"#our-test-dataset\" aria-label=\"our test dataset permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Our Test Dataset</h2>\n<p>In our example, we’re going to use WIDER FACE dataset</p>\n<blockquote>\n<p>Instruction how to get dataset is <a href=\"https://github.com/burnpiro/tiny-face-detection-tensorflow2#dataset\">Here</a></p>\n</blockquote>\n<p>This dataset contains over 32k images and weights around 2GB so we don’t really want to keep it in the memory all the time. This dataset is used to teach object detection models so it contains bounding boxes for every face on the image.</p>\n<h3 id=\"data-structure\"><a href=\"#data-structure\" aria-label=\"data structure permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data structure</h3>\n<p>Dataset is already split into <strong>Train</strong> and <strong>Validation</strong> so we don’t have to do it again. We have two folders: <strong>WIDER_train</strong> and <strong>WIDER_val</strong>. The image description is stored in <code class=\"language-text\">wider_face_train_bbx_gt.txt</code> and <code class=\"language-text\">wider_face_val_bbx_gt.txt</code>. Here is an example of one of the images</p>\n<figure class=\"image\">\n  <a class=\"gatsby-resp-image-link\" href=\"/static/1fbd4b1b30208290b1eca0b275330f4d/1f853/22_Picnic_Picnic_22_277.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 960px;\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAQDAQL/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgD/2gAMAwEAAhADEAAAAcvNGMs6tKlHcA//xAAbEAADAAMBAQAAAAAAAAAAAAAAAQIDETIEE//aAAgBAQABBQJ+SkfDQpbH1e0RjlTjt5p5G2f/xAAYEQACAwAAAAAAAAAAAAAAAAAAAhARQf/aAAgBAwEBPwEofI//xAAYEQACAwAAAAAAAAAAAAAAAAAAAhAhQf/aAAgBAgEBPwEoXY//xAAgEAACAgEDBQAAAAAAAAAAAAABEQACMRAhQkFhcYGR/9oACAEBAAY/AmLVImQNme04fYW/Jhqm+s4+zLVvhRAnT//EABoQAQEBAQEBAQAAAAAAAAAAAAERACExUUH/2gAIAQEAAT8hCSIfHuaFlCrzKEUWVm6uuFD6TIGAg67DzEaW9fTQY8IaL8x+7m7+b//aAAwDAQACAAMAAAAQ0yf+/8QAGREBAAIDAAAAAAAAAAAAAAAAAQAQESEx/9oACAEDAQE/EDDyELdP/8QAGBEBAQADAAAAAAAAAAAAAAAAAQAQETH/2gAIAQIBAT8Q0nZYcP/EAB8QAQADAAEEAwAAAAAAAAAAAAEAESFBMVFhsXGh8f/aAAgBAQABPxB/CyU4iVGsKBcbOHPuEo8gKgeodoDWhqDbRvzxLxQlgkxegEwln4ab9PA1W2ebIthFF9SeoJHAePU//9k=&apos;); background-size: cover; display: block;\"></span>\n    <img class=\"gatsby-resp-image-image\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\" alt=\"Image Example\" title src=\"/static/1fbd4b1b30208290b1eca0b275330f4d/b3ee8/22_Picnic_Picnic_22_277.jpg\" srcset=\"/static/1fbd4b1b30208290b1eca0b275330f4d/3bc27/22_Picnic_Picnic_22_277.jpg 240w,\n/static/1fbd4b1b30208290b1eca0b275330f4d/98431/22_Picnic_Picnic_22_277.jpg 480w,\n/static/1fbd4b1b30208290b1eca0b275330f4d/b3ee8/22_Picnic_Picnic_22_277.jpg 960w,\n/static/1fbd4b1b30208290b1eca0b275330f4d/1f853/22_Picnic_Picnic_22_277.jpg 1024w\" sizes=\"(max-width: 960px) 100vw, 960px\">\n  </span>\n  </a>\n  <figcaption>Image source: WIDER FACE dataset</figcaption>\n</figure>\n<p>Description for that image in <code class=\"language-text\">.txt</code> file is as follows:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">22--Picnic/22_Picnic_Picnic_22_277.jpg\n3\n196 410 74 114 1 0 0 0 0 0 \n344 404 62 88 1 0 0 0 0 0 \n634 222 58 86 1 0 0 0 0 0 </code></pre></div>\n<p>It might seem unclear at first but everything is explained in Dataset’s Readme file:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">File name\nNumber of bounding box\nx1, y1, w, h, blur, expression, illumination, invalid, occlusion, pose</code></pre></div>\n<p>So our image contains 3 boxes. The first two numbers are X and Y coordinates followed by box width and height. After that we have more information about the face inside the box, we’re not going to use those ones because our goal is just object detection (face detection) but feel free to check Readme file for properties description.</p>\n<h2 id=\"models-input-and-output\"><a href=\"#models-input-and-output\" aria-label=\"models input and output permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model’s input and output</h2>\n<p>Now after we know how our dataset looks like we need to figure out what is an input and output of our <strong>Model</strong>.</p>\n<blockquote>\n<p>You can skip this section if you want. It’s not necessary to know anything more than the input and output size of the model to construct training examples.</p>\n<ul>\n<li>Input - <strong>224x224x3</strong></li>\n<li>Output - <strong>7x7x5</strong></li>\n</ul>\n<p>Imho, it’s beneficial to understand it but not required. I’ve selected this model because most of the guides are using simple examples from regression networks and it’s hard to find a solution for a complex one.</p>\n</blockquote>\n<p>For this example we’re going to use <strong>MobileNetV2</strong> (<code class=\"language-text\">mobilenet_v2_0.75_224</code> to be precise), our model has input size of <strong>224x224x3</strong> (width x height x RGB). So every example in our sentence has to produce input of that size.</p>\n<p>Output, on the other hand, is completely up to us. We’re using MobileNet as a feature extractor that gives us output from the last Conv layer of <strong>7x7x240</strong>. We want to keep 7x7 grid and our detection requires only 5 values per grid (because we have only one class). In the end, our output should look like <strong>7x7x5</strong> (grid width x grid width x number of classes times 5).</p>\n<p>I’m not going to discuss how this network works, you can easily find any tutorial on CNNs and how to use them as a feature extractor for object detection (maybe some other guide in the future).</p>\n<p>This is how our model looks like at the end:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 224, 224, 3) 0                   \n________________________________________________________________________\n                         \n----- Rest of MobileNetV2 ------\n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 240)    960         block_16_project[0][0]           \n__________________________________________________________________________________________________\n\n----- Our Layers conected to MobileNet output------    \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 7, 7, 5)      1205        activation[0][0]                 </code></pre></div>\n<p>Now it should be clear that our Dataset should generate examples like:</p>\n<ul>\n<li>Input - <strong>224x224x3</strong></li>\n<li>Output - <strong>7x7x5</strong></li>\n</ul>\n<h2 id=\"extend-sequence-class\"><a href=\"#extend-sequence-class\" aria-label=\"extend sequence class permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Extend Sequence Class</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Data generator boilerplace</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DataGenerator</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>Sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">,</span> config_path<span class=\"token punctuation\">,</span> debug<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Sequence initialization</span>\n        \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__len__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Should return Sequence length</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__getitem__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Returns preprocessed data</span></code></pre></div>\n<h3 id=\"initialization\"><a href=\"#initialization\" aria-label=\"initialization permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Initialization</h3>\n<p>The first thing we need to implement is data initialization. </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">,</span> config_path<span class=\"token punctuation\">,</span> debug<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Sequence initialization</span>\n        </code></pre></div>\n<p>Because dataset description is located in two different files (one for training and one for validation) we need to pass paths to the folder with images (<code class=\"language-text\">file_path</code>) and the path to our dataset spec (<code class=\"language-text\">config_path</code>). <code class=\"language-text\">debug</code> options allow us to display additional messages when processing dataset.</p>\n<p>Inside <code class=\"language-text\">__init__</code> method we have access to <code class=\"language-text\">self</code> object. This object represents our sequence and we want to initialize some default values on it.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">self<span class=\"token punctuation\">.</span>boxes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\nself<span class=\"token punctuation\">.</span>debug <span class=\"token operator\">=</span> debug\nself<span class=\"token punctuation\">.</span>data_path <span class=\"token operator\">=</span> file_path</code></pre></div>\n<ul>\n<li><code class=\"language-text\">self.boxes</code> is going to store all boxes definitions from dataset</li>\n<li><code class=\"language-text\">self.debug</code> enables <strong>debug</strong> mode</li>\n<li><code class=\"language-text\">self.data_path</code> stores path to images for later processing</li>\n</ul>\n<p>After initialization we need to check if paths are valid (if not there is no reason to create Sequence).</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>isfile<span class=\"token punctuation\">(</span>config_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"File path {} does not exist. Exiting...\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>config_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>isdir<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Images folder path {} does not exist. Exiting...\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>When everything is correct we can start reading config file</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>config_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fp<span class=\"token punctuation\">:</span>\n    image_name <span class=\"token operator\">=</span> fp<span class=\"token punctuation\">.</span>readline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    cnt <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">while</span> image_name<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># image_name - relative path to our image</span>\n        <span class=\"token comment\"># in this loop we have to process each image definition</span></code></pre></div>\n<p>We’re going to read this file line by line but as you remember file is structured in a specyfic way:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">File name\nNumber of bounding box\nx1, y1, w, h, blur, expression, illumination, invalid, occlusion, pose</code></pre></div>\n<p>So after reading <strong>File name</strong> and <strong>Number of bounding box</strong> we need to use that number to know how many lines to read as bounding boxes definition.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>config_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fp<span class=\"token punctuation\">:</span>\n    image_name <span class=\"token operator\">=</span> fp<span class=\"token punctuation\">.</span>readline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    cnt <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">while</span> image_name<span class=\"token punctuation\">:</span>\n        num_of_obj <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>fp<span class=\"token punctuation\">.</span>readline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_of_obj<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            obj_box <span class=\"token operator\">=</span> fp<span class=\"token punctuation\">.</span>readline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span>\n            x0<span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> h <span class=\"token operator\">=</span> get_box<span class=\"token punctuation\">(</span>obj_box<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> w <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\"># remove boxes with no width</span>\n                <span class=\"token keyword\">continue</span>\n            <span class=\"token keyword\">if</span> h <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\"># remove boxes with no height</span>\n                <span class=\"token keyword\">continue</span>\n            self<span class=\"token punctuation\">.</span>boxes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x0<span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        line <span class=\"token operator\">=</span> fp<span class=\"token punctuation\">.</span>readline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        cnt <span class=\"token operator\">+=</span> <span class=\"token number\">1</span></code></pre></div>\n<p>First thing we have to do inside <code class=\"language-text\">while</code> loop is to extract how many boxes there are. To do this we’re calling <code class=\"language-text\">int(tf.readline()</code> which returns next line value as integer. We’re using this numer to iterate through next <code class=\"language-text\">num_of_obj</code> lines. Each line values are separated by empty string so we have to split values before processing <code class=\"language-text\">obj_box = fp.readline().split(&#39; &#39;)</code>. We’re interested in first 4 values from each line but those values have to be integers. To extract those values it’s easier to create helper function <code class=\"language-text\">get_box</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Input: [x0, y0, w, h, blur, expression, illumination, invalid, occlusion, pose]</span>\n<span class=\"token comment\"># Output: x0, y0, w, h</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_box</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    x0 <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    y0 <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    w <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    h <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> x0<span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> h</code></pre></div>\n<p>This function receives list of strings and returns 4 integers we need. After that we’re appending our box to Sequence object <code class=\"language-text\">self.boxes.append((line.strip(), x0, y0, w, h))</code> and read next line.</p>\n<p>Everything seems fine and we should be ready to move to the next part, but if we try to execute this code it will fail.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">ValueError: invalid literal <span class=\"token keyword\">for</span> int<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> with base 10: <span class=\"token string\">'0--Parade/0_Parade_Parade_0_630.jpg\\n'</span></code></pre></div>\n<p>Did we make a mistake in the code? No we didn’t. We just didn’t explore our dataset carefully enough. If we jump to our <strong>.txt</strong> file and find line with that sentence it’s much clearer what just happen.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0--Parade/0_Parade_Parade_0_452.jpg\n0\n0 0 0 0 0 0 0 0 0 0 \n0--Parade/0_Parade_Parade_0_630.jpg</code></pre></div>\n<p>We didn’t antycipated there are images wihtout faces and because of how our iteration is designed it’s not going to skip line with zeros after reading <code class=\"language-text\">num_of_obj = 0</code>. Knowing that we can create quick fix just after for loop:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> num_of_obj <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n    obj_box <span class=\"token operator\">=</span> fp<span class=\"token punctuation\">.</span>readline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span>\n    x0<span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> h <span class=\"token operator\">=</span> get_box<span class=\"token punctuation\">(</span>obj_box<span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>boxes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x0<span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>That way, when there are no faces on image we’re going to create empty example.</p>\n<h3 id=\"return-length-of-the-dataset\"><a href=\"#return-length-of-the-dataset\" aria-label=\"return length of the dataset permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Return length of the dataset</h3>\n<p>That should be easy… But it isn’t :) When implementing <code class=\"language-text\">__len__</code> method we need to remember that training works in batches. Because of that, we have to divide the number of boxes by our batch size and return that instead of just the length of our array.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">__len__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> math<span class=\"token punctuation\">.</span>ceil<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>boxes<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> cfg<span class=\"token punctuation\">.</span>TRAIN<span class=\"token punctuation\">.</span>BATCH_SIZE<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Notice that we’re using a mysterious config called <code class=\"language-text\">cfg</code>. This is just an <code class=\"language-text\">EasyDict</code> dictionary that holds our dataset settings. You don’t have to worry about it right now, I’ll show you its definition at the end. For now, just assume that it stores all config values.</p>\n<h3 id=\"returning-items\"><a href=\"#returning-items\" aria-label=\"returning items permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Returning items</h3>\n<p>Till now we’ve managed to create our Sequence but we still didn’t define how to process images in the dataset. Each box in Sequence has 5 values:</p>\n<ul>\n<li>path to image</li>\n<li>x value for box center</li>\n<li>y value for box center</li>\n<li>box width</li>\n<li>box height</li>\n</ul>\n<p><code class=\"language-text\">__getitem__(self, idx)</code> method should return two values (input, output). But because we’re working in batches those values will be arrays with multiple images and corresponding boxes.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">__getitem__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    boxes <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>boxes<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">*</span> cfg<span class=\"token punctuation\">.</span>TRAIN<span class=\"token punctuation\">.</span>BATCH_SIZE<span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> cfg<span class=\"token punctuation\">.</span>TRAIN<span class=\"token punctuation\">.</span>BATCH_SIZE<span class=\"token punctuation\">]</span></code></pre></div>\n<p>First, we have to extract boxes definition from given <strong>idx</strong> to <strong>idx + BATCH_SIZE</strong>. So if our <strong>BATCH_SIZE</strong> is <strong>16</strong> and <strong>idx</strong> is <strong>0</strong> then we’re processing boxes from <strong>0</strong> to <strong>16</strong>.</p>\n<p>Now we have to define zeros matrix for input and output</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">batch_images <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>INPUT_SIZE<span class=\"token punctuation\">,</span> cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>INPUT_SIZE<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\nbatch_boxes <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>GRID_SIZE<span class=\"token punctuation\">,</span> cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>GRID_SIZE<span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li><code class=\"language-text\">batch_images</code> contains images and has a size of <strong>16x224x224x3</strong>. </li>\n<li><code class=\"language-text\">batch_boxes</code> contains expected output in a grid and has size of <strong>16x7x7x5</strong>.</li>\n</ul>\n<p>Now we have to iterate over our batch and process each example.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> row <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    path<span class=\"token punctuation\">,</span> x0<span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> h <span class=\"token operator\">=</span> row</code></pre></div>\n<p>First, we have to create input from image path. To do that we’re going to use <code class=\"language-text\">tf.keras.preprocessing.image.load_img</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">proc_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>load_img<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data_path <span class=\"token operator\">+</span> path<span class=\"token punctuation\">)</span>\n\nimage_width <span class=\"token operator\">=</span> proc_image<span class=\"token punctuation\">.</span>width\nimage_height <span class=\"token operator\">=</span> proc_image<span class=\"token punctuation\">.</span>height\n\nproc_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>load_img<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data_path <span class=\"token operator\">+</span> path<span class=\"token punctuation\">,</span>\n                                               target_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>INPUT_SIZE<span class=\"token punctuation\">,</span> cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>INPUT_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nproc_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>img_to_array<span class=\"token punctuation\">(</span>proc_image<span class=\"token punctuation\">)</span>\nproc_image <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>proc_image<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\nproc_image <span class=\"token operator\">-</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>applications<span class=\"token punctuation\">.</span>mobilenet_v2<span class=\"token punctuation\">.</span>preprocess_input<span class=\"token punctuation\">(</span>proc_image<span class=\"token punctuation\">)</span>\n\nbatch_images<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> proc_image</code></pre></div>\n<p>For each image, we need to extract original width and height to be able to scale <strong>x0, y0, w, h</strong> of our box. That’s why we’re calling this method twice (second time with <code class=\"language-text\">target_size</code> set to our <strong>224x224</strong>). In the end, our processed image is stored in <code class=\"language-text\">batch_images</code>.</p>\n<p>Next, we have to deal with box position and size. Original values are integers and represent a point on the original image. What we need to do is to scale them into <strong>&#x3C;0,1></strong> values. That’s why we need <code class=\"language-text\">image_width</code> and <code class=\"language-text\">image_height</code> from the original image.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    image_width <span class=\"token operator\">=</span> proc_image<span class=\"token punctuation\">.</span>width\n    image_height <span class=\"token operator\">=</span> proc_image<span class=\"token punctuation\">.</span>height\n\n    <span class=\"token comment\"># make sure none of the points is out of image border</span>\n    x0 <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>x0<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    y0 <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>y0<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n    x0 <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>x0<span class=\"token punctuation\">,</span> image_width<span class=\"token punctuation\">)</span>\n    y0 <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>y0<span class=\"token punctuation\">,</span> image_height<span class=\"token punctuation\">)</span>\n\n    x_c <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>GRID_SIZE <span class=\"token operator\">/</span> image_width<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> x0\n    y_c <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>cfg<span class=\"token punctuation\">.</span>NN<span class=\"token punctuation\">.</span>GRID_SIZE <span class=\"token operator\">/</span> image_height<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> y0\n\n    floor_y <span class=\"token operator\">=</span> math<span class=\"token punctuation\">.</span>floor<span class=\"token punctuation\">(</span>y_c<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># handle case when x i on the corner</span>\n    floor_x <span class=\"token operator\">=</span> math<span class=\"token punctuation\">.</span>floor<span class=\"token punctuation\">(</span>x_c<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># handle case when y i on the corner</span>\n\n    batch_boxes<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> floor_y<span class=\"token punctuation\">,</span> floor_x<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> h <span class=\"token operator\">/</span> image_height\n    batch_boxes<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> floor_y<span class=\"token punctuation\">,</span> floor_x<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> w <span class=\"token operator\">/</span> image_width\n    batch_boxes<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> floor_y<span class=\"token punctuation\">,</span> floor_x<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> y_c <span class=\"token operator\">-</span> floor_y\n    batch_boxes<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> floor_y<span class=\"token punctuation\">,</span> floor_x<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> x_c <span class=\"token operator\">-</span> floor_x\n    batch_boxes<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> floor_y<span class=\"token punctuation\">,</span> floor_x<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span></code></pre></div>\n<p>This section applyies extra validation to be sure that our point lays inside the image. Except that we’re calculating relative position of that point to whatever grid cell it is in. </p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d5813d7e1967e2a979a22e9eee965cbd/59fbd/grid.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 960px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAA7DAAAOwwHHb6hkAAADV0lEQVQ4y2WU11OiQRDE9/9/tKyyyvBgOEsMJVrGMgcUEyASVUDMiDmDp33z2+Pzru7mxcFvd6anu2ddZ2en0um0hoaGNDk5qWQyqZ6eHq2urioej6u7u1tra2va2dlRV1eXtra2tLCwoFAopL29PQ0PD2t0dFT5fF6tra1yFCPOz8/1+Pjo83wupyByf+XZbNb//fz81NHRkc8vLy91fX3tc5o6kFFsZmZGkUhExycnClvHpDUqHR9r2PK0FSocHno0BwcHisVimpiY0ImdnZub0+Lioq6urtTb2yvHmCCjWDyR0O3NjWZHRlS0caqGYsaKlK1YxS5MTU3p4uLCj0eRu7s7ra+vexpeX199QwdnxLGhuXt48Pm+fVClIr29KR8OS6en/v+pxtlaraZDa0KcnZ3Z0YrPNzY25BCAjmG7OD07q9z2tvqbm7VmgiTtUl9bm2Lj44qnUvphZxFqeXlZg4ODymQyXpBx+06Djo4OOdQk9qx7sVyWnp8VteI31ao+jIp1KDFhal9fitjZN0ONEAhAICqACHRwdCRKxaKqt7c+TxrRH4xvv3eN26/GyInG2ZeXl+8iZQPB2AT2cvgMa4SNt2nrkLWRB5qaFNnc1K6pG2pp+TOynUXhpaUlDQwM/Ddye3u7HFUD6GWQ2EibpvKDqeaJnp7W8/6+floeNUXr9bqqRkfCHBH4NBBofn5eLuACn1XsIJExwutGgTlWaUPyaQ4gYo2zT09P3yYvlUrejwTWc6wTH/EQPks11IysrChh4zFmNBr1o0IPAPBgf3+/P4s7xsbGvOHbzBEOUxL8A9MSCPX2/v4blRVizGC1iAcTLFjZQqHghSFWDIRj0dlNLqIcpsVnWAM1EQDOGBNkFGMJQE0juAQpwdY5Xg0Wnd3kAgRjWtDQADW5BC2MCTKKjZhwoIMm/HdqgkKf4wkiIJbd9KKYHYL4Ow+QgIxiwerxMBCbZjWHGIzHq8GicwBveRsZN+RYAzURgEIgBhlnoQyKeML6+vrkuMAPxkUgFh2jMi4XAtMyAWrSBKSMCTKK4eX7+3tPjwtWiI+vDTMHRv03xwlBnDbWETAU86tpyB3PNgLwODI+TxCvBgjozDqxAZgWn2EN1EQAOGPMQLhme6V+AfRWdbCpI0moAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"Object\"\n        title=\"\"\n        src=\"/static/d5813d7e1967e2a979a22e9eee965cbd/f570d/grid.png\"\n        srcset=\"/static/d5813d7e1967e2a979a22e9eee965cbd/0783d/grid.png 240w,\n/static/d5813d7e1967e2a979a22e9eee965cbd/782f4/grid.png 480w,\n/static/d5813d7e1967e2a979a22e9eee965cbd/f570d/grid.png 960w,\n/static/d5813d7e1967e2a979a22e9eee965cbd/59fbd/grid.png 1018w\"\n        sizes=\"(max-width: 960px) 100vw, 960px\"\n      />\n  </span>\n  </a></p>\n<p>Default values for this point might be:</p>\n<ul>\n<li>x = 0.35 (relative to top left corner)</li>\n<li>y = 0.35 (relative to top left corner)</li>\n</ul>\n<p>But our output requires position in relation to the grid cell (one which contains the point). Because of that new coordinates are as follows:</p>\n<ul>\n<li>x = 0.5 (relative to cell top left corner)</li>\n<li>y = 0.5 (relative to cell top left corner)</li>\n</ul>\n<p>In the end, we’re saving those values inside i-th output and 3x3 grid cell (rest of them remains zero). Notice that the <strong>width</strong> and the <strong>height</strong> of the box are still scaled to the full image.</p>\n<p>After we process all examples in the batch we need to only return both arrays</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">return</span> batch_images<span class=\"token punctuation\">,</span> batch_boxes</code></pre></div>\n<p>To use our generator just create instance of it and pass right paths</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_datagen <span class=\"token operator\">=</span> DataGenerator<span class=\"token punctuation\">(</span>file_path<span class=\"token operator\">=</span>cfg<span class=\"token punctuation\">.</span>TRAIN<span class=\"token punctuation\">.</span>DATA_PATH<span class=\"token punctuation\">,</span> config_path<span class=\"token operator\">=</span>cfg<span class=\"token punctuation\">.</span>TRAIN<span class=\"token punctuation\">.</span>ANNOTATION_PATH<span class=\"token punctuation\">)</span>\nval_generator <span class=\"token operator\">=</span> DataGenerator<span class=\"token punctuation\">(</span>file_path<span class=\"token operator\">=</span>cfg<span class=\"token punctuation\">.</span>TEST<span class=\"token punctuation\">.</span>DATA_PATH<span class=\"token punctuation\">,</span> config_path<span class=\"token operator\">=</span>cfg<span class=\"token punctuation\">.</span>TEST<span class=\"token punctuation\">.</span>ANNOTATION_PATH<span class=\"token punctuation\">,</span> debug<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>now we can fit our data for training</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>fit_generator<span class=\"token punctuation\">(</span>generator<span class=\"token operator\">=</span>train_datagen<span class=\"token punctuation\">,</span>\n                        epochs<span class=\"token operator\">=</span>cfg<span class=\"token punctuation\">.</span>TRAIN<span class=\"token punctuation\">.</span>EPOCHS<span class=\"token punctuation\">,</span>\n                        callbacks<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token comment\"># your callbacks for TF],</span>\n                        shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                        verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Here is a full code for <strong>DataGenerator</strong> Class:\n<a href=\"https://gist.github.com/burnpiro/c3835a1f914545f2034f4190b1e83153\">https://gist.github.com/burnpiro/c3835a1f914545f2034f4190b1e83153</a></p>\n<h2 id=\"summary\"><a href=\"#summary\" aria-label=\"summary permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Summary</h2>\n<p>If you’re working with complex datasets (or just really large ones) it’s a good idea to think about Sequences and create your won Sequence Class for data generation. It’s efficient (multithreading out of the box) and easy to maintain way you’ll appricieate, especially when working with the team of engineres and version controll.</p>\n<p>This code is just an example, your implementation may (and probably will) look different. Everything depends on specific problems and structure of the dataset but imho it’s a lot easier to define data processing inside class than using C like approach you can find inside Tensorflow guides.</p>\n<p>Have a Happy New Year and see you in 2020!!!</p>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/2019/12/how-to-create-tensorflow-2-sequence-dataset-from-scratch"}}}