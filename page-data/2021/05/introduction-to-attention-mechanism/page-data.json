{"componentChunkName":"component---src-templates-post-template-js","path":"/2021/05/introduction-to-attention-mechanism","result":{"data":{"markdownRemark":{"fields":{"slug":"/2021/05/introduction-to-attention-mechanism","tagSlugs":["/tag/machine-learning/","/tag/transformers/","/tag/attention/","/tag/how-to/"],"readTime":{"text":"35 min read","minutes":34.61666666666667}},"frontmatter":{"description":"How Attention was created? Why does it work and why it is one of the most important things in ML right now?","tags":["Machine Learning","Transformers","Attention","How To"],"date":"2021-05-10","title":"Introduction to Attention Mechanism"},"html":"<p>The attention mechanism is one of the most important inventions in Machine Learning, at this moment (2021) it’s used to achieve impressive results in almost every field of ML, and today I want to explain where it came from and how it works.</p>\n<p>Before even start explaining Attention we have to go back and see the problem which Attention was supposed to solve. Before 2015, there was an issue with RNN which was occurred when the input sequence was really long.</p>\n<figure>\n    <div  class=\"center-all\" id=\"pure-rnn-sts-diagram\">\n        <rnn-process></rnn-process>\n    </div>\n    <figcaption>Figure 1: Sequence-to-sequence with RNN, Designed base on <a href=\"https://arxiv.org/abs/1409.3215\" target=\"_blank\"><i>“Sequence to sequence learning with neural networks”</i>, NeurIPS 2014</a> Paper</figcaption>\n</figure>\n<p>This solution works fine as long as the sentence is short. After the decoder is done with its job, we’re left with the <strong>context vector <em>c</em></strong> and the <strong>initial decoder state <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></strong>. Those two vectors have to <em>“summarize”</em> the whole input sequence because we’re going to feed them into the decoder part of our model. You can treat the context vector as something that transferring information between the encoded sequence and the decoded sequence.</p>\n<p>For long sentences, like <strong>T=100</strong>, it is highly probable that our context vector <em><strong>c</strong></em> is not going to be able to hold all meaningful information from the encoded sequence. Consider this quote:</p>\n<blockquote>\n<p>“In a way, AI is both closer and farther off than we imagine. AI is closer to being able to do more powerful things than most people expect — driving cars, curing diseases, discovering planets, understanding media. Those will each have a great impact on the world, but we’re still figuring out what real intelligence is.” - <strong>Mark Zuckerberg</strong> in <em><strong>“Building Jarvis”</strong></em></p>\n</blockquote>\n<p>It is a lot easier to compress the first sentence to the context vector than to do the same for a whole quote. We could create longer and longer context vectors but because RNNs are sequential that won’t scale up. That’s where the Attention Mechanism comes in.</p>\n<p>The idea is to create <strong>a new context vector every timestep</strong> of the decoder which attends differently to the encoded sequence.</p>\n<figure>\n    <div class=\"center-all\" id=\"rnn-sts-with-attention-diagram\">\n        <rnn-with-attention></rnn-with-attention>\n    </div>\n    <figcaption>Figure 2: Sequence-to-sequence with RNN (with Attention), Designed base on <a href=\"https://arxiv.org/abs/1409.0473\" target=\"_blank\"><i>“Neural machine transla$on by jointly learning to align and translate”</i>, NeurIPS 2015</a> Paper</figcaption>\n</figure>\n<p>This time we’re computing an additional context vector on every step of the decoder. Let us go through one whole step to explain what is happening.</p>\n<h3 id=\"1-compute-alignment-scores\"><a href=\"#1-compute-alignment-scores\" aria-label=\"1 compute alignment scores permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Compute alignment scores</h3>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 641px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 35.569422776911075%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABe0lEQVQoz5WRTW/TQBCG/TeBKz8KBAcuqE1LhaoICSUIiSKqgtpDHWzRNLbjfJDYzjqpv2MneZhsyoEjK4322RnpnZl3Df7j7HY71GJBv9/HdT3Gkwm+7xOGEdvtliLPMbI4YjUb0zQ1y6lPvlK6GD/yRvhvXvSIY4XreTiuy1DEBo6reRYEpFmGYX//ylX7lN2m4dv5Mc7ttZ7m8vwI1zzwVbuF17vRnCQJq4cHZvM5k+mUqqooJYqyJMtkQse26Lw/I0sTPr474eJTVwoZH1pHfOl2SNOU9vFbnVdK6XUt2+burs9gMKReb/R2TdNQiqjhVTUXwYKyrvk8nWPHK13oTmZYaklRFHTGvw8sjfZr5eJVnmfi4w/yInz0d6tv40Ww5PkoxBqNeGbe80rennj0xHJ4HR746a8hL4OYJIoIJZSKJX+PP3ojgjfaW5HUn2b0ZKJT02Kvf3Lbw4yU7tQyf/7Li1h83rBer6llm6oqRcwTPnzWXmwffwB5eAWyTtFJEAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alignment scores\" title=\"alignment scores\" src=\"/static/6ef8e4bb13f4ea32573f64297f12d1c5/60ba3/alignment-scores.png\" srcset=\"/static/6ef8e4bb13f4ea32573f64297f12d1c5/733ef/alignment-scores.png 320w,\n/static/6ef8e4bb13f4ea32573f64297f12d1c5/70d1f/alignment-scores.png 640w,\n/static/6ef8e4bb13f4ea32573f64297f12d1c5/60ba3/alignment-scores.png 641w\" sizes=\"(max-width: 641px) 100vw, 641px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 3: Alignment Scores for <b>t=1</b>, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>At <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> we’re going to use <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> decoder state to computer alignment scores. To compute the alignment score for every encoder state we’re using a function that is called <em>alignment function</em> but it’s just an MLP (MultiLayer Perceptron). Each alignment score can be treated as “how much <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">h_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> is useful in predicting the output in the state <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>”. The alignment function outputs a scalar value which is a real number and we cannot use it just like that, we have to normalize those values using the softmax function.</p>\n<h3 id=\"2-compute-attention-weights\"><a href=\"#2-compute-attention-weights\" aria-label=\"2 compute attention weights permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Compute attention weights</h3>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 754px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 46.551724137931025%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAAB30lEQVQoz3WSS5PSQBSF87Mt9/4FdlapOxYuLN3oMDOUOEUBjgzCECAJQ0JIIO/3qxOON10y6sJb1dVdlb5fzjm3BVvbQpoMkPguVnfXqIocujjD/nEKVhbYDG+R0rckTSEpCuStgrUs077F8XSCZdt8nRwHURxDsHQVs+FXsCLDpH8FVpV4EheQFw+oGcN0cIM0DJBmOSzLguN5SNMMqraHbTvIsgxFUSBvV55DCKMYunkEq2vs9jp2qorlWoLlevzi3jD55ZQUbiQJkqxA0zTIpDYIQ+QELMsSNfUzEiA4xh7SdMwVLkcDblNdLaBLIpqaQRzfIY8j3qSQzflShETg1XpNuwzP99E0DS4ltI3fPr6Hbx3R675FTcBHiuD77Rc0rMJV9x0c84CCgKZpUnZP0A4Gh1RVxS23yto6n88Q2iDH9/c82F6/D9d18TCfYzga8fPn3jWPwTAMqLTruo4tDaaFXWy2oGfgTVLg1SnA5GDipeFB8Xx0djpeewlkyu+FQT8IY2RBgDBKaDAE1roEMn+b/APjlmd+iDcrGRoNp/NzCZvC/7CR8Uk7wIkidOYidnGCIk3o6WQIAg++/4PUBc+gfxQ27QTJWlsRPYu2GEGrJObnhKL4X11Af9cv9l2fPA86to0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"attention weights\" title=\"attention weights\" src=\"/static/4fdd50fe95d5574d013b9f8ac70a863a/dbdb8/attention-weights.png\" srcset=\"/static/4fdd50fe95d5574d013b9f8ac70a863a/733ef/attention-weights.png 320w,\n/static/4fdd50fe95d5574d013b9f8ac70a863a/70d1f/attention-weights.png 640w,\n/static/4fdd50fe95d5574d013b9f8ac70a863a/dbdb8/attention-weights.png 754w\" sizes=\"(max-width: 754px) 100vw, 754px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 4: Attention weights for <b>t=1</b>, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>Output from the softmax function is normalized so all the numbers sum up to 1. Those outputs are called <strong>Attention weights</strong> and as the name says, they show the model “how much it should attend to corresponding hidden state”.</p>\n<h3 id=\"3-compute-context-vector\"><a href=\"#3-compute-context-vector\" aria-label=\"3 compute context vector permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Compute context vector</h3>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 968px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 40.392561983471076%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABfUlEQVQoz4WRWW/bQAyE9f//SdHjqUBfiqYx0sNI7UqKLUu2tLLu6Hbcxjp8fF0JRR56IAMQwyUWQw6pZHmO7Tgslkvc7RZN1xCui6qqOEJQliVZllEUBWEYju8Bl8uFP3E+n1E8V+BYKzYrgyrPsIwFdZGPvK/Lp48DDocDdV2PYmVVEScJfhCw9T2iOKZpGpTQsVjPpyymN8RijTmbEtkmxu0XUneNH0ZYlsXGtlmZJoEUGAQHYdfbUu12NG1L+zuUSnYKowjP98dQdZ1C2hrsPuz3f1nqupbT6UTf97QyPx6PY32odV0nJ3QdhKFjqt9IPMFyfksWepjajCoJuM9yhHDxpa1MruQ5KL5lcHfzEXXyAUdX+T65wtbmzK7e40gupLUkiUnTSu6wH84xWv5fKNruB6+9iBcbweQ+55VpS854aW64Lmrahx1VvZe7+0rXx08X/teVxwlXjw1v3IC3fsQnKfTOC/ic5iNfpwWnx5/UsmlV3UnB5FnBX7GQV3rAFYCnAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"context vector\" title=\"context vector\" src=\"/static/d9f826e1dae94728bc94f201b82cd0ff/5b692/context-vector.png\" srcset=\"/static/d9f826e1dae94728bc94f201b82cd0ff/733ef/context-vector.png 320w,\n/static/d9f826e1dae94728bc94f201b82cd0ff/70d1f/context-vector.png 640w,\n/static/d9f826e1dae94728bc94f201b82cd0ff/5b692/context-vector.png 968w\" sizes=\"(max-width: 968px) 100vw, 968px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 5: Context vector calculation for <b>t=1</b>, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>Now a lot of things happen (3 steps in the diagram above). First, we multiplied every attention weight by corresponding hidden state (<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>h</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">a_{1,1} \\times h_{1,1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8694379999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>×</mo><msub><mi>h</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">a_{1,2} \\times h_{1,2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8694379999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>…). Then, all of the results are summed to use as a <strong>context vector <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">c_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></strong>.</p>\n<blockquote>\n<p><strong>Note:</strong><br/>\nYou’ve probably noticed that at this point “context vector” is actually a “context scalar” but this is just because we decided to have only 1D output (easier to show and understand for now). I’m going to switch to vectors when we get to abstracting attention to its own layer.</p>\n</blockquote>\n<h3 id=\"4-compute-first-output\"><a href=\"#4-compute-first-output\" aria-label=\"4 compute first output permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Compute first output</h3>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 778px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 63.49614395886889%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACm0lEQVQ4y22TWW/TUBCF87OReOYH8IKEELyAWAUICSFQoWzpQps2SeNA0qTeYsdbaju2EzeJk49xUqoidaTRvfbonnvOzLmVTucPpmmy/2sf13U5OqqhtBUMw6Ba/bmu2baNZVnrLPdlrdyXsVqt1vkvKuXhMAypCdB8PqeltDAHA9I0XV9SFEtuCs/zpFZcgV4Bnh5WsTQVo3mApWvYvd/oyjHu0Ear75OcB0RxTDAaEcvqyxpG0Zrhcrm5bHmNZeVg+yND0+BkZxtbVrPbprVfZeR7NH9+IQ48dJHYUhR6p6c0Wi1UTaMtyhaLxX+sS9CKZg5whb7jB9QbDTq9Prr8830f2/UYJ8mNkkfC9B+gEweMsmjDsFs/xLUt9N9NdPUMs9+l324KQx9VqZNGIeE1yefhOdM8XwOWPV+yojFp486CDeDnl4/Re11+vH2GMzBp7X7n6OsnAtdh+9UTsjDAGjqciFRNpHZFtivMS/AszSg799R8w9lE3wAey3Q7nQ471Sqm9Gpvb49GvU6/3+fz1ha2NL90QSRZrkEQXPWrZFmGJQon0+kG8I4TsnWicFu1qEnv7h6f8MCP2G02uXU2YHfo4ssBW1j2xAG9/gv8oEMUJfLdw9BVPP8Ds/nGl5X7csiZLbjXM3CnOdt+yGvTIRGP3ZOamk0Qw8kACiaTRLJJnvss5gVpljEQex0evmCaORvARFNKASRaCxYXrBKfxOyui6n8K6Y3T7mMizShXd1hKAM8DTRBEdskBw8pxjbjXw8oUo9c/ca0857VLCWrPaKIzcueLS/NK8cuDZ1Ln6ePn2Mkfd4lW+RFTmViKayEWWY2WS5mpGabsVrnYhwQ//nBxNP/e7PX326RyyBGIYPYZtepYcQOfwEk7MRp8opVIQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"first output\" title=\"first output\" src=\"/static/3eb1c3d89a6d2ecfb8b664bd06567aba/4fa3d/first-output.png\" srcset=\"/static/3eb1c3d89a6d2ecfb8b664bd06567aba/733ef/first-output.png 320w,\n/static/3eb1c3d89a6d2ecfb8b664bd06567aba/70d1f/first-output.png 640w,\n/static/3eb1c3d89a6d2ecfb8b664bd06567aba/4fa3d/first-output.png 778w\" sizes=\"(max-width: 778px) 100vw, 778px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 6: Decoder&apos;s output for <b>t=1</b>, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>At the end of the first timestep, we can finally compute the first output from the decoder. That output is computed using context vector <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">c_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>, previous decoder’s state <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>, and start token <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">y_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>. Interesting thing is that in that whole process we don’t have to train <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>f</mi><mrow><mi>a</mi><mi>t</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">f_{att}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> as a separate model. The <strong>whole process is differentiable</strong>, so we can just backpropagate through the computational graph.</p>\n<h3 id=\"5-and-repeat\"><a href=\"#5-and-repeat\" aria-label=\"5 and repeat permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. And repeat…</h3>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 850px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60.11764705882353%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAACaUlEQVQoz2WS2WvbYBDE/f+/FgqFQGkf00D7kJY2DYGkTtI4p235UKRIsizrtGRblyUf+fWTQhJoFpYVn2B2dmYaQRAg38vIssxd+w7btmk2m0wmT3M0GuG6bv1eteM4mKZJHMdU9fj4WPdzNTRNQ1Xusawx5sggTRL6PYlETKnbYbVa8X8VRUEURW8Aq9kwlSHS6RFav4NydYrv2nSPf2GbBvLFCaFlYFoTpF4PVVXpDQcYFWvB9AmFF7CaoSOYDTp36A8KSl8SLEe0ry6YWFb9PpsGLAWj6sSKddWe5zEV71UtVwXlevXKMAzDepvj2HhCq6HQ0tD1+tu2J+R5/ubk5XL5ouEk9XCz6SugNuhy8XsfpXvL3fEBoe/R3N/Dty0uD7/jGiqO59OVJHRdQxPLotmMLMtqkOPkHHmpvgJa+gPnhwdIt9eciTns9zn4useDMOrk53d6tzd4vl+zHo8t4bCNYRhUZs4E8Jl0ySTyXgFvZws+B3OORuN6ysKA927I0A/4oI+5THM2aUKWlwSBSpy08MUVVZTiRYJrN0USrNqcx+2WxiBd8mnk8Nfx2VFMnDjhnWygRzN2ZI1WtKBYzJkvUmGGSpK2a72rTC6ynKubb8I49cXwxjqZkpuSUHpOanTqH6l2DZuSfNyDLHybw7IkFaaUusFEpKI/1ylDn7UxorHyZdLOHiu3R9LeZSuA49ZH1rFH1vlCYd08bd9u2IqTqsoql6OQ7Y8DImvI/voUr9VksbtHY1NklEnEpsgp0znbVUlsPVDEEZlnkAUWzwl+Dm/lcGWK77gousKfwQXtXpup0P0fnrx6rgHrNDQAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"t 2\" title=\"t 2\" src=\"/static/ea7bae6af4a2ce44430365d4f20301f6/861bd/t%3D2.png\" srcset=\"/static/ea7bae6af4a2ce44430365d4f20301f6/733ef/t%3D2.png 320w,\n/static/ea7bae6af4a2ce44430365d4f20301f6/70d1f/t%3D2.png 640w,\n/static/ea7bae6af4a2ce44430365d4f20301f6/861bd/t%3D2.png 850w\" sizes=\"(max-width: 850px) 100vw, 850px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 7: New context vector for <b>t=2</b>, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>At the timestep <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span> only thing we have to do is to <strong>change the input to calculate the alignment scores from <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> to <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></strong>. Using the same process we compute new scores (<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mrow><mn>2</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">e_{2,1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mrow><mn>2</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">e_{2,1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>…) and attention weights (<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mrow><mn>2</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">a_{2,1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mrow><mn>2</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">a_{2,1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>…). Then multiply new attention weights and encoder’s hidden states to compute the new context vector <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>c</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">c_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>. At this point, the whole process just runs in the loop until the decoder produces <em>[STOP]</em> token (sometimes called <em>[EOS]</em> token, eng. End Of Sentence).</p>\n<h2 id=\"attention-weights-visualization\"><a href=\"#attention-weights-visualization\" aria-label=\"attention weights visualization permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Attention weights visualization</h2>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 717px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 105.02092050209204%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAAC70lEQVQ4y3VUyUprQRC9xiGKUzZGcCGCcQBBQXEWXKkBN0mWCrpyk09w5Q+4ceUixnnAqFtFRPwEd4obFaPRJIoDTnE4j1Pvdefe5L4LRfftrj5ddepUG/j3/f7+ivH7+fnB6+urXrfzMY9mH8PO+evrC+fn5xo8Ho8jGo3i+/tbr9GXY+Z5I/M2BXh6eqoPn52d4eTkBM/Pz7J2c3OD9/d3JBIJmfOil5cX3N7ewsgE+/z8lIjoyDWm/vj4iGQyievrazw9PeHq6gqpVEpAefHHx4ecFcBMnnjrwcEBQqEQFhYWMDc3h3A4LDY/P4+lpSVsbGyILS4uYnl5GVtbW2I8pyPkjZwfHh7C7/djeHgYhmHYWlFREQoKCrLW29vb04CxWAz39/cSUU1NDTY3N9HU1CSODocDeXl5KCwshNPpFDD+K8vNzRW//v5+a8osRiQSkc3q6moEg0E0NjYKSH5+PkpLS1FeXi7AvITAXFcRDgwM/I2QRjB+6+vr2sHlcmFychJutxtlZWXwer2oqqqSvZycHO2n5j09PWkdEvDh4UHIVmlyLC4ulijoPDs7i7a2Nsu+ed7d3Q2Dcri8vMTFxQXu7u50hOYDHR0dwm1fX59tkSyALARFe3x8LDqjDMxO5Ovo6AhDQ0NZKdoCshOY7tvbm6S+vb0tm6pydO7t7RU++T82NgafzycFygS0cKiqvbq6mpWy+X90dBRTU1NoaWnR0VoAlWTYRtTi2tqabJaUlGSlyJEFIs/j4+M6E7UvKZs7hQ2+srKiucskX9EwODgocurq6rL4khqtQ3JJUCUbO51xpMg5ZxfNzMxgZGRE+1lS5itD+fBBsOPQbOoCthofi0AgIP8iKwXIN422s7Mjm+RK8UPjXLUfrbKyUvwop+npaQmgs7MzDaie/N3d3f9GxkPsZVpFRYWYKiCjnZiYSANS4OyU/f191NbWoqGhAXV1dWL19fV6pHk8Hhmbm5vR2toqfFJOe3t7+AMe7dGqDQAo+gAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"attention weights heatmap\" title=\"attention weights heatmap\" src=\"/static/fffc70b061aee6d776d625efda7e885f/6f2d1/attention-weights-heatmap.png\" srcset=\"/static/fffc70b061aee6d776d625efda7e885f/733ef/attention-weights-heatmap.png 320w,\n/static/fffc70b061aee6d776d625efda7e885f/70d1f/attention-weights-heatmap.png 640w,\n/static/fffc70b061aee6d776d625efda7e885f/6f2d1/attention-weights-heatmap.png 717w\" sizes=\"(max-width: 717px) 100vw, 717px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 8: Attention weights for English to French translation, Source:  <a target=\"_blank\" href=\"https://arxiv.org/abs/1409.0473\">Neural Machine Translation by Jointly Learning to Align and Translate</a> </figcaption>\n</figure>\n<p>In the original paper, there is a simple visualization of the attention weights <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">a_{i,j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> generated when translating the English sentence <em>“The agreement on the European Economic Area was signed in August 1992.”</em> into French <em>“L’accord sur la zone économique européenne a été signé en août 1992.”</em>. This visualization shows us a couple of interesting things.</p>\n<p>The first thing is a diagonal pattern which tells us that model put more attention to corresponding French word from the same position. The second thing is more interesting and it is the phrase <em>“European Economic Area”</em> which in French has reverse order <em>“la zone économique européenne”</em>. We can see that when generating <code>la</code> token model puts more attention on <code>the</code> and <code>Area</code>, then when generating the <code>zone</code> token it attends to <code>Area</code> and <code>Economic</code> (ignoring <code>European</code>). Another interesting observation is <em>“a été signé”</em> where when generating <code>a</code> and <code>été</code> tokens, the model attends to both <code>was</code> and <code>signed</code> (it makes sense in French because we need to know an exact variation of the word <code>étre</code>).</p>\n<p>This heatmap is important because we didn’t tell the model which words it should attend to, it learned this by itself. Additionally, we’ve got a kind of interpretability of the model’s decision.</p>\n<h2 id=\"attention-doesnt-know-that-input-is-a-sequence\"><a href=\"#attention-doesnt-know-that-input-is-a-sequence\" aria-label=\"attention doesnt know that input is a sequence permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Attention doesn’t know that input is a sequence</h2>\n<p>You probably started to worry about what happened with my information from the last step:</p>\n<p><em>“We’re not using the fact that h vector is an ordered sequence. It is used as unordered set instead. To solve this we have to add a positional encoding to each element”</em></p>\n<p>I’ve written a piece on positional encoding as a separate article because there is too much information to squeze into this one. If you’re interested please check <a href=\"https://erdem.pl/2021/05/understanding-positional-encoding-in-transformers\">Understanding Positional Encoding in Transformers</a>.</p>\n<p>This is still a thing but instead of solving that problem, make use of it to abstract attention mechanism and use it for something different than a sequence of text. What about describing images with attention? There is a paper from the same year called <a href=\"https://arxiv.org/abs/1502.03044\"><em>“Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”</em></a> that uses attention on CNN’s embedding to generate image captioning with the help of an RNN decoder.</p>\n<figure>\n    <div class=\"center-all\" id=\"rnn-imtos-with-attention-diagram\">\n        <image-with-attention></image-with-attention>\n    </div>\n    <figcaption>Figure 9: Image Captioning with Attention (still RNN), Designed base on <a href=\"https://arxiv.org/abs/1502.03044\" target=\"_blank\"><i>“Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”</i>, ICML 2015</a> Paper</figcaption>\n</figure>\n<p>In this paper, the authors are proposing a solution based on convolutional feature extraction instead of the standard RNN encoder network. We’re using those features from CNN to compute state and then to compute alignment scores for every timestep of the RNN decoder. As in the previous example, I’m going to walk you through the whole process, but you probably are able to understand it base on the interactive diagram above :)</p>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 637px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 67.66091051805337%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAAC00lEQVQ4y4WS2W/TaBTF86/xwL/AA/AwgJAKFHgBKsTbSCAQEjMtm0olUIFhhkoUqQ10gaY0BSpoKV2y0DUlSx3HjRNncWzHzo9rl0UZJPiko3vt735H595zQ61Wi9/BP27TwSzrmEaJRqW8GwWu2wzuv9WF+N35WlhSFWITw8Qiz4i/GmHh5TCfpsepCWkbYbPZxLIsTNP8jnq9vhsFjUYDx3UpFxQSkWGSr56zEh0lHgmzOj1GTVS3EfoP/Q9FUXg/O8tyLEY8kWBjc1NiMiD2Swu5NEsvh1gWlUsTz1h4MURMyH8i9BUUCiqZbJa1jU1WVlfJZDKsb2wE/7a2ttDLBrqSIzkZJiEka29eSOvhIJoyz2+EPkKO4wQtfm/zf7FardKwbYpKlg8jT5gfe8rM8ABzI4N8kFzX1HbCX/vxw2XPsbF0jZqW5/3UJF61TH5zjbiMKLj3vN2WWy0Pp2njyIMgfs09z20jd4TXb06X+CmvYkjuI5VOUy79cDpUr1V5Oz3F6+lJolMTzMy8JhqNoBc12TGPol8sm5A0LU5mNbryJbq2i5wRnJdcabrkMzmKemVXYbm4w0BfH3euXKH30mUe3LzJwxvXUTNpFFEyFA6jiUkr0tEf2yU6tSqnBMdUg05BzpELzxQDl4XOEsIdjX96url14QKD3bd51NPD/b+uEZufY3RsjHv9/SzNzfF0YYlDn1VO5Ip0ZnfoELWdgnepHMsfw2zn+8TEJCFD1xns66W76xzXz55joPc2dy9fQv2cYnV9nX8fP0bZSrFYMzmslDipVThdqHBc1J0qGKQbLlY1S8l4i22rhJTtHBd7/ubIwf3s27OXPx/9x9XxCbK5bLA28WQSu2KQsJscSCl0COkxUXhUlHZkNDK202ZeyCiXiMzPMjo+Sv/de8wsLrBoVKg47YVFGX6k1iBat4nWLKbqluQWVdffBn+9vMDlLzr79fJyuipDAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cnn alignment\" title=\"cnn alignment\" src=\"/static/7ff8d4eda4962bdfba3a56aa4018896d/c4799/cnn-alignment.png\" srcset=\"/static/7ff8d4eda4962bdfba3a56aa4018896d/733ef/cnn-alignment.png 320w,\n/static/7ff8d4eda4962bdfba3a56aa4018896d/c4799/cnn-alignment.png 637w\" sizes=\"(max-width: 637px) 100vw, 637px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 10: Alignment score calculation from extracted features, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>We’re assuming that CNN is already trained and produces our 3x3 grid. We’re going to use that initial grid to predict the initial hidden state <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> (sometimes it could be randomly generated or even set to 0). Now we have to pass the same grid and <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> to the alignment function to calculate corresponding alignment score for each value of the grid <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>f</mi><mrow><mi>a</mi><mi>t</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>h</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">e_{t,i,j} = f_{att}(s_{t-1}, h_{i,j})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>. That gives us alignment scores for <strong>t=1</strong> timestep. As in the previous example, each alignment score is a scalar which tells us “how important is given feature in the current timestep”.</p>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1080px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 39.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABkElEQVQoz42Qy27TUBRF/atMGLUS7U8wKUVkyoAJc1okHlKhtANAIuGhOEnjJErixI7TmGs7ceJXYi+OTcsAkOBIV9u2vNfd+2j8Nts0ZdZrMe18Y2a0qvckjnH6bSz5Zhs6WZqQZRlhGLLZbFiJJvJfnudoyvNwXRelFJEY43XI1eVrmmcnoq+Y21MG/R6di5e03jyn/e4FUbgkTTPMyYSxaVYaJwmx+LXReMxwNKLU+fWCwFO0BdQUc0fAc9uibxi0BKSfnVbA9TKo2iQCWUiYMlk5URSh/aq63ZJKjVRuWQ4Nhp/eYzUbBJJ8t8twBldYXR271yYT0G6XS8q0gpb1S39V2ZyMmUxNoW9+3lrAZZpzopa8jTIs5ckec/53tCdHD3hae4T+pcHneh19bLLv+NyxFXtOwCBQqMVX8iKjKAo5+Y3+/WhH9w54fHxM4+MHLs7PaXQNDh2Pu/Z3DgTYdWeEfl2AaZXg1nj7/EfCw/09as9OMVchshR82UfNX3PfXfFQhfg3nrzS4p+VfwD7ZlK2CVLchgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cnn attention weights\" title=\"cnn attention weights\" src=\"/static/b2041c2d11e89a9c2e5a2913684fdfbc/9d22c/cnn-attention-weights.png\" srcset=\"/static/b2041c2d11e89a9c2e5a2913684fdfbc/733ef/cnn-attention-weights.png 320w,\n/static/b2041c2d11e89a9c2e5a2913684fdfbc/70d1f/cnn-attention-weights.png 640w,\n/static/b2041c2d11e89a9c2e5a2913684fdfbc/9d22c/cnn-attention-weights.png 1080w\" sizes=\"(max-width: 1080px) 100vw, 1080px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 11: Attention weights, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>With alignment scores calculated we need to apply softmax to normalize scores to some probability distribution that sums to one.</p>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1082px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 47.134935304990755%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAAB3UlEQVQoz5WRy27TUBRF/amMCl+AxJAfaMsAMWBSEAMGKAHKpCGtKhpBE5I274Tmbefl2LEdx/EjibO4NiUSgglH2rK05bvuPvtK/GPWvsesd4faaaLLXcJwh+fYaPeeMRqw2+1Yr9d4nrdXGIZIm80Gy7KYz+fx1w8CloZO7fyU8lmSH5nP6LpOu1GNvdJZgtb1JVtxzjBNur0e/cEAZTjE930kU5jtToe7Votev89kqqJPJ1QuPlFMvacugKPRiFrxhmr6owAmY6Af+IQipW3bWIvFr81EYimKuV9VGIHQeuWg1UvI+a+MKze4rkvgLpGF1y7m0AddLG/BxFbjVJGis9G2kjZTReSuiCzjie6iWQqlVwGn5pIrN2Cmz0VnEF1tO078T8uXydnVv/qX0skEr4+OePviOc1qmUI2S2Gi8mhq8mA058lsiblUWVj1OEnU9W4L+qKNot3GkOiBfktKvDrh6cFDXh4f8/36GxepFFftLgdjIwY+Hlv0hw2MeZ6BLNNsCPBmR6OVRRsX74Eh8QpRwvPMF54dHvIhl0cXXYWibG2z5Y1Y98SweSdk2Q4rx0NRFJTxmK14db1UpmK2cLfuPmUM5D8mEB33BFSr1nBuC2RsEcI3/gD+BPq1mawpreqvAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cnn attention mask\" title=\"cnn attention mask\" src=\"/static/1a4c792fa2776dca76fd230ac853bec9/2fd86/cnn-attention-mask.png\" srcset=\"/static/1a4c792fa2776dca76fd230ac853bec9/733ef/cnn-attention-mask.png 320w,\n/static/1a4c792fa2776dca76fd230ac853bec9/70d1f/cnn-attention-mask.png 640w,\n/static/1a4c792fa2776dca76fd230ac853bec9/2fd86/cnn-attention-mask.png 1082w\" sizes=\"(max-width: 1082px) 100vw, 1082px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 12: Compute context vector and generate first output, <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>Now all we have to do is to compute <a href=\"https://en.wikipedia.org/wiki/Hadamard_product_(matrices)\">Hadamard product</a> (element-wise multiplication, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>×</mo><msub><mi>a</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{i,j} \\times a_{t,i,j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> …) and sum everything to get a context vector <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">c_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>. The rest works exactly like in the previous example so we use context vector <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">c_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>, start token <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">y_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>, and initial decoder state <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> and pass it through <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>g</mi><mi>U</mi></msub></mrow><annotation encoding=\"application/x-tex\">g_U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">U</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> function to calculate <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> state and achieve some output token <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">y_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>.</p>\n<blockquote>\n<p><strong>Note</strong><br/>\nThe sum is not required at this point, I’m just doing it to have the same shape of the context vector as in the previous example. We could easily use a 3x3 matrix as an input to the <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>g</mi><mi>U</mi></msub></mrow><annotation encoding=\"application/x-tex\">g_U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">U</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> function.</p>\n</blockquote>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1080px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 48.05555555555556%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACMElEQVQoz12Sy3PSYBTF+VvVce04XXTjUqcbF260486FKxetdrRTWstUrfhqC7ZAG6CQQMkD8iKBBEj4eZPOME4zuXPyncl9fecUuPMkizl6s06vdpZHHAYkaYrRvszP2sUpoTsiXS4JgoAwDBlnOJmwWCwoOI6DbdtkOI0i4ukE5fiA8/331A53MLQOvf4NDeEuDj7wd2+LUa9DKs0Nw6DTVemoal5jNptRaLZaKM0mLUFNEl3Hpv61SKW4nUf/ukm706Va2qVa3OL00zsstZ1vs5TJTdNiMpnm50gGKixldHlJkoT5fM5MSKfdQCkfoZ+foGtd4lmM1ZXClV90hZt4NoPQxA09pvEUI7DydfOVraGJaRmSFOVdslXOZgnFoUtZ0JDugR8SCA50PZ8mWaZ8tsuMEo9wOWXf+S5ckucX3rx4wdvNV9QqZ1QrFS41jXXD5d6Nzf2Bw6k3Jok0uXQXXTcwpGgWlesS7sTC9kya1g8RbnFb8Pmjx7ze2ODk+BvFvT1O6g3WTY8HustD06dsjhjbJZlQR1HauXi+KNpSPhKNDW4MFbW7u3JJ4cnaGi+3d1AzlX0fL4rZdEOemi7Phj4Xjkvg+NiCV8oVqQgRD3SuRaxBNCSxRiiNmnybtwXn4ruF/LT8z4tZUuazNBcsizTnVU2V+zZJj47Run/4klSZ7Jfo139yGP8WYUWUVZVV8vKu11dcHEe59zzbYTAcoOht+r0efuCJ6qJ0mvAPPmThv052b8oAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cnn second timestep\" title=\"cnn second timestep\" src=\"/static/d0e833aab2689ef7be2fed2deaa0c538/9d22c/cnn-second-timestep.png\" srcset=\"/static/d0e833aab2689ef7be2fed2deaa0c538/733ef/cnn-second-timestep.png 320w,\n/static/d0e833aab2689ef7be2fed2deaa0c538/70d1f/cnn-second-timestep.png 640w,\n/static/d0e833aab2689ef7be2fed2deaa0c538/9d22c/cnn-second-timestep.png 1080w\" sizes=\"(max-width: 1080px) 100vw, 1080px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 14: Second timestep (<b>t=2</b>), <a target=\"_blank\" href=\"https://erdem.pl/2021/04/introduction-to-attention-mechanism\">Source: erdem.pl</a> </figcaption>\n</figure>\n<p>The same as before, we’re using newly generated <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> state to compute new alignment scores <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mrow><mn>2</mn><mo separator=\"true\">,</mo><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">e_{2,i,j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>, which then are normalized with softmax and computed into context vector <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>c</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">c_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>. The process stops when the decoder produces <em>[STOP]</em> token as an output.</p>\n<h2 id=\"visualization-of-the-attention-weights\"><a href=\"#visualization-of-the-attention-weights\" aria-label=\"visualization of the attention weights permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Visualization of the attention weights</h2>\n<p>The same as in sequence to sequence translation we are able to visualize attention weights in this case. I’m going to use one of the examples provided by the authors.</p>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 963px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 63.966770508826585%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAADW0lEQVQ4y22Ta0ybVRjH369+cR9IyJzZ1JjFjGjcEBUXCQ7YzIQqc2s3lIvpxm1jS5kBpxDIiJgAFpBKEbbiYNlcB1gKLWVlwLZ2IBS6TS4tlwECMS4CmnjjUvj5choTP+wk58P7zy/nPc/veY40MtuPpc9Io7OODreZzeX1jqItL6ayRkdldQVz87P4fD4u1dfK3zqKtF/Q2uZn7/Y4qNCXU23QY2y6ilR2IZOolGDC1C+RUhQrIFNzA0/tCGDX7p08GfgEnd0dbGxsUH2hgoQTHyBJEgnqY4Jts5lJPBFHwLYtBO3ZiVRgPMd5UzJXnGcwNJ3z/7XPQaQinJjDEeTka5idmxG5Z2aYrLzTJCUfpn/QKbLf/lygwXqVqOhQjqfEIV1xldF4L48b7gIsLeUC6nZ0EvHOXsIigikqzmdl+R+WV5Yp0RUS/f4+irV5zM9NCfb+yACF2lwyNB9Ra6hEcg/9gMNl5+7ATdzDvQKa+WmaRtN1zJbvMVtNLC4tCIebpbe1t2LvtOEd9wh2YnIci1y2zW6Rb92L9O2lGt47omDrjkBeDwvxN2VsBHVKPMGhLxPw9Bb5oJsi11V+yZuRb/B80DOc0qSKzDXQQ9TBcJ59YTuh4SFIc4+mqamv5IAiTHbjF/3HX79jv23lZKaasMgQBgb7RN5g/g71yXjZbZTsNstf8tAgH+ecQZOdKjdKidR+x0JhaQ6nzyZRUnxeQFNzk+jrylCnK/kw/l3GvB5W11ZJlj0dijtA5NuvUvh5nmD1Bh0xqkjUaUdQKqORvOMjuNw9DNzrZWT0RwEtLP5Kr8she2mh65adpaVFfOs+bjk7MbVc51rDZQbd/X49E6OyQxNNzdfkEWpFqpUdxioVHEtU8Vn+JwL65dHPdN2xMzT2gPueQbnDf+NbW6NKHvSMs+lUGb7G+3CUxy0p+9NMtj0XiCohlkNHo0XYbrey57UXycrVyH4ymJ2fZnV1hd2vBLFfsY+vvimhy3FDsJvd//+WMrLSURzdT0OzAX2VVkC3e7rZvmurLP8tVHEH8XiGRX4qOw1VYgxFpbkYjfUiW19fF6/ovy1Z7c2YbUbcD5zYbM3+2ZoaQ3+xlFJ5kFPTkng4OSFyZ38XF+t05Bdk09HR9tgD/wXqrgLmfFd1WgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"show attend soft example\" title=\"show attend soft example\" src=\"/static/8872ff9181c036664ce5831cb2949278/b1718/show-attend-soft-example.png\" srcset=\"/static/8872ff9181c036664ce5831cb2949278/733ef/show-attend-soft-example.png 320w,\n/static/8872ff9181c036664ce5831cb2949278/70d1f/show-attend-soft-example.png 640w,\n/static/8872ff9181c036664ce5831cb2949278/b1718/show-attend-soft-example.png 963w\" sizes=\"(max-width: 963px) 100vw, 963px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 15: Image attention visualization, white regions have higher value of the attention weight, Source:  <a target=\"_blank\" href=\"https://arxiv.org/abs/1502.03044\">Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention</a> </figcaption>\n</figure>\n<p>As you can see this is not an ideal solution for explaining a model but still could give you a kind of intuition about what is happening. Especially when we look at the tokens like <code>frisbee</code> or <code>park</code> when the model attends to those exact objects. In the case of the token <code>woman</code>, both people on the image save similar attention weights but that’s still ok because the model could decide which one is the subject and how to name that person.</p>\n<p>There is one more type of attention called <strong>hard attention</strong> where instead of using the softmax function, we’re selecting a feature with the highest alignment score and using that feature’s value as a context. It requires some changes in the training process which I’m not going to discuss right now. Here is an example of hard attention.</p>\n<figure>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 974px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 65.91375770020534%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAADk0lEQVQ4yyWSaVNTZwCF7+/otNXWYgvIYlJMIGERwyIE2QVboQWtTiMMsi9CqEhZalutSGaINYhAQwCRTRRZau0gQthmkOl0E2tlqR212g+EJPD0cntn3i93znvmPec8woPFezQPGzAOfE3TUD0bOJmdnaaiSk/Vl5WUf17K4qOHvHz5D5U1p6kW/5WdKWH0h2G2PuO3Bs7UfCbpmlpNCJfNFYQdlxN+QklSaZAosdPebsbF7U12Kz14y/V17lvvsby8hJvnDrwVHmzb+RrnLp6VDGPi9uPq7cIOt20cPpKEcP5GDYVtqXRYc6k369jctHOtpwOZ2pOohL2ERqqYm5tmeXUJeYA34TGBaPYruXL1kmSYmBpPQNgeQrW+FBZnIXTNXaJlooiRhSo6LBWiZJP+wV4i4oJJPRpP7RflPP7jEUsrT9AmaEhK0VKqz2Z87C52hx1dzidEJ4aQlXuE7i4Lwi+LC4zPjjI+M8rE3F3RboM/nzzm9shNRu7cZmj0Fs+eP2NtbY2R74cYvjPI4MgAvz38VUyzydj4j5J260zPWRFOlRUgU3ihDFCgiQjCtm6jr+86crG/gBA1cj9PpmYmefp0leAQFYGhaqnHhssGKfJHacn4BvmIOm90J48hdPa0ERIVJAoVRMTuw2Zbo/9mL8cy09HGa1D4ezI9a2VldVm85IVGG4DM1w2D8YJkmHQ4HtW+PSgDvTiekYZwtq4axV5PAkO80Wj8sK3Z6OyxoIn2JzzaD5nchanJCanDXcqd4qtlJH8YSW93Jw6ng+hDkcjVrkSLA35zvhZhK7vpagOtbY20WZpxOp389PMCRlM95vYmGpuMrKws8+rfVzQ2G2kxmxi41c3i4u84N5x091/jSouR670W5udnEdo7zRScyqVYX8Dpaj12u52p6Unyik5SUl5EXkm2NMCLF88pLsunrKKEzLwT3BjslyLXGc5RpM8nuzCLiw0XEHLzM3Fx384u+Xv4qL2kUSzt36H0l6EKVojAvsGEdVwC29XjbQn27e+KYNf9D/aB2HAJ7HfcRbDTRbAL9Hn4iIVq4wJJ+Tge+/o6li4zaRkppOsOolC5MzNjlcDeLQ4UttVtlJqW1kaJ2YTUWPxD3xf7Vol85iN8VVdLwgeRZOakYzIZcDgcEmcxyeEc/fQQB5OiWHgwz19/r5KYckCEPYGKyiIm7o9JYOcUZ4iwR5FfrKO/r4v/AHsArqV0+OAnAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"show attend hard example\" title=\"show attend hard example\" src=\"/static/89ddc733bf475797151dd73913b6e131/f6062/show-attend-hard-example.png\" srcset=\"/static/89ddc733bf475797151dd73913b6e131/733ef/show-attend-hard-example.png 320w,\n/static/89ddc733bf475797151dd73913b6e131/70d1f/show-attend-hard-example.png 640w,\n/static/89ddc733bf475797151dd73913b6e131/f6062/show-attend-hard-example.png 974w\" sizes=\"(max-width: 974px) 100vw, 974px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n    <figcaption>Figure 16: Hard attention visualization, white regions are the regions which model attends to, Source:  <a target=\"_blank\" href=\"https://arxiv.org/abs/1502.03044\">Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention</a> </figcaption>\n</figure>\n<p>As you can see, the caption has changed. Now it’s saying <em>“A man and a woman playing frisbee in a field.”</em> instead <em>“A woman is throwing a frisbee in a park.”</em>. Attention regions are not fully related to the generated token (as in soft attention), when generating token <code>frisbee</code> model attends to the child.</p>\n<h2 id=\"lets-abstract-the-attention\"><a href=\"#lets-abstract-the-attention\" aria-label=\"lets abstract the attention permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Let’s abstract the Attention</h2>\n<p>Now, when you know what the Attention is, we can start working on abstracting the idea to create so called <em>“Attention Layer”</em>. </p>\n<h3 id=\"references\"><a href=\"#references\" aria-label=\"references permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>References:</h3>\n<ul>\n<li>Sutskever et al, “Sequence to sequence learning with neural networks”, NeurIPS 2014 <a href=\"https://arxiv.org/abs/1409.3215\">https://arxiv.org/abs/1409.3215</a></li>\n<li>Bahdanau et al, “Neural machine transla$on by jointly learning to align and translate”, ICLR 2015 <a href=\"https://arxiv.org/abs/1409.0473\">https://arxiv.org/abs/1409.0473</a></li>\n<li>Xu et al, “Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”, ICML 2015 <a href=\"https://arxiv.org/abs/1502.03044\">https://arxiv.org/abs/1502.03044</a></li>\n</ul>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n</style>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The attention mechanism is one of the most important inventions in Machine Learning, at this moment (2021) it’s used to achieve impressive results in almost every field of ML, and today I want to explain where it came from and how it works."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Before even start explaining Attention we have to go back and see the problem which Attention was supposed to solve. Before 2015, there was an issue with RNN which was occurred when the input sequence was really long."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"div","properties":{"className":["center-all"],"id":"pure-rnn-sts-diagram"},"children":[{"type":"text","value":"\n        "},{"type":"element","tagName":"rnn-process","properties":{},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 1: Sequence-to-sequence with RNN, Designed base on "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1409.3215","target":"_blank"},"children":[{"type":"element","tagName":"i","properties":{},"children":[{"type":"text","value":"“Sequence to sequence learning with neural networks”"}]},{"type":"text","value":", NeurIPS 2014"}]},{"type":"text","value":" Paper"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This solution works fine as long as the sentence is short. After the decoder is done with its job, we’re left with the "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"context vector "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"c"}]}]},{"type":"text","value":" and the "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"initial decoder state "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]}]},{"type":"text","value":". Those two vectors have to "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“summarize”"}]},{"type":"text","value":" the whole input sequence because we’re going to feed them into the decoder part of our model. You can treat the context vector as something that transferring information between the encoded sequence and the decoded sequence."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"For long sentences, like "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"T=100"}]},{"type":"text","value":", it is highly probable that our context vector "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"c"}]}]},{"type":"text","value":" is not going to be able to hold all meaningful information from the encoded sequence. Consider this quote:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"“In a way, AI is both closer and farther off than we imagine. AI is closer to being able to do more powerful things than most people expect — driving cars, curing diseases, discovering planets, understanding media. Those will each have a great impact on the world, but we’re still figuring out what real intelligence is.” - "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Mark Zuckerberg"}]},{"type":"text","value":" in "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"“Building Jarvis”"}]}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"It is a lot easier to compress the first sentence to the context vector than to do the same for a whole quote. We could create longer and longer context vectors but because RNNs are sequential that won’t scale up. That’s where the Attention Mechanism comes in."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The idea is to create "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"a new context vector every timestep"}]},{"type":"text","value":" of the decoder which attends differently to the encoded sequence."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"div","properties":{"className":["center-all"],"id":"rnn-sts-with-attention-diagram"},"children":[{"type":"text","value":"\n        "},{"type":"element","tagName":"rnn-with-attention","properties":{},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 2: Sequence-to-sequence with RNN (with Attention), Designed base on "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1409.0473","target":"_blank"},"children":[{"type":"element","tagName":"i","properties":{},"children":[{"type":"text","value":"“Neural machine transla$on by jointly learning to align and translate”"}]},{"type":"text","value":", NeurIPS 2015"}]},{"type":"text","value":" Paper"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This time we’re computing an additional context vector on every step of the decoder. Let us go through one whole step to explain what is happening."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"1-compute-alignment-scores"},"children":[{"type":"element","tagName":"a","properties":{"href":"#1-compute-alignment-scores","ariaLabel":"1 compute alignment scores permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"1. Compute alignment scores"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 641px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 35.569422776911075%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABe0lEQVQoz5WRTW/TQBCG/TeBKz8KBAcuqE1LhaoICSUIiSKqgtpDHWzRNLbjfJDYzjqpv2MneZhsyoEjK4322RnpnZl3Df7j7HY71GJBv9/HdT3Gkwm+7xOGEdvtliLPMbI4YjUb0zQ1y6lPvlK6GD/yRvhvXvSIY4XreTiuy1DEBo6reRYEpFmGYX//ylX7lN2m4dv5Mc7ttZ7m8vwI1zzwVbuF17vRnCQJq4cHZvM5k+mUqqooJYqyJMtkQse26Lw/I0sTPr474eJTVwoZH1pHfOl2SNOU9vFbnVdK6XUt2+burs9gMKReb/R2TdNQiqjhVTUXwYKyrvk8nWPHK13oTmZYaklRFHTGvw8sjfZr5eJVnmfi4w/yInz0d6tv40Ww5PkoxBqNeGbe80rennj0xHJ4HR746a8hL4OYJIoIJZSKJX+PP3ojgjfaW5HUn2b0ZKJT02Kvf3Lbw4yU7tQyf/7Li1h83rBer6llm6oqRcwTPnzWXmwffwB5eAWyTtFJEAAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"alignment scores","title":"alignment scores","src":"/static/6ef8e4bb13f4ea32573f64297f12d1c5/60ba3/alignment-scores.png","srcSet":["/static/6ef8e4bb13f4ea32573f64297f12d1c5/733ef/alignment-scores.png 320w","/static/6ef8e4bb13f4ea32573f64297f12d1c5/70d1f/alignment-scores.png 640w","/static/6ef8e4bb13f4ea32573f64297f12d1c5/60ba3/alignment-scores.png 641w"],"sizes":["(max-width:","641px)","100vw,","641px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 3: Alignment Scores for "},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"t=1"}]},{"type":"text","value":", "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"At "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"t=1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.61508em;vertical-align:0em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2777777777777778em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mrel"]},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2777777777777778em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.64444em;vertical-align:0em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"text","value":" we’re going to use "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"−"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_{t-1}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.638891em;vertical-align:-0.208331em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mbin","mtight"]},"children":[{"type":"text","value":"−"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.208331em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" decoder state to computer alignment scores. To compute the alignment score for every encoder state we’re using a function that is called "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"alignment function"}]},{"type":"text","value":" but it’s just an MLP (MultiLayer Perceptron). Each alignment score can be treated as “how much "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"h_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.84444em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" is useful in predicting the output in the state "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":"”. The alignment function outputs a scalar value which is a real number and we cannot use it just like that, we have to normalize those values using the softmax function."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"2-compute-attention-weights"},"children":[{"type":"element","tagName":"a","properties":{"href":"#2-compute-attention-weights","ariaLabel":"2 compute attention weights permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"2. Compute attention weights"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 754px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 46.551724137931025%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAAB30lEQVQoz3WSS5PSQBSF87Mt9/4FdlapOxYuLN3oMDOUOEUBjgzCECAJQ0JIIO/3qxOON10y6sJb1dVdlb5fzjm3BVvbQpoMkPguVnfXqIocujjD/nEKVhbYDG+R0rckTSEpCuStgrUs077F8XSCZdt8nRwHURxDsHQVs+FXsCLDpH8FVpV4EheQFw+oGcN0cIM0DJBmOSzLguN5SNMMqraHbTvIsgxFUSBvV55DCKMYunkEq2vs9jp2qorlWoLlevzi3jD55ZQUbiQJkqxA0zTIpDYIQ+QELMsSNfUzEiA4xh7SdMwVLkcDblNdLaBLIpqaQRzfIY8j3qSQzflShETg1XpNuwzP99E0DS4ltI3fPr6Hbx3R675FTcBHiuD77Rc0rMJV9x0c84CCgKZpUnZP0A4Gh1RVxS23yto6n88Q2iDH9/c82F6/D9d18TCfYzga8fPn3jWPwTAMqLTruo4tDaaFXWy2oGfgTVLg1SnA5GDipeFB8Xx0djpeewlkyu+FQT8IY2RBgDBKaDAE1roEMn+b/APjlmd+iDcrGRoNp/NzCZvC/7CR8Uk7wIkidOYidnGCIk3o6WQIAg++/4PUBc+gfxQ27QTJWlsRPYu2GEGrJObnhKL4X11Af9cv9l2fPA86to0AAAAASUVORK5CYII='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"attention weights","title":"attention weights","src":"/static/4fdd50fe95d5574d013b9f8ac70a863a/dbdb8/attention-weights.png","srcSet":["/static/4fdd50fe95d5574d013b9f8ac70a863a/733ef/attention-weights.png 320w","/static/4fdd50fe95d5574d013b9f8ac70a863a/70d1f/attention-weights.png 640w","/static/4fdd50fe95d5574d013b9f8ac70a863a/dbdb8/attention-weights.png 754w"],"sizes":["(max-width:","754px)","100vw,","754px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 4: Attention weights for "},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"t=1"}]},{"type":"text","value":", "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Output from the softmax function is normalized so all the numbers sum up to 1. Those outputs are called "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Attention weights"}]},{"type":"text","value":" and as the name says, they show the model “how much it should attend to corresponding hidden state”."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"3-compute-context-vector"},"children":[{"type":"element","tagName":"a","properties":{"href":"#3-compute-context-vector","ariaLabel":"3 compute context vector permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"3. Compute context vector"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 968px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 40.392561983471076%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABfUlEQVQoz4WRWW/bQAyE9f//SdHjqUBfiqYx0sNI7UqKLUu2tLLu6Hbcxjp8fF0JRR56IAMQwyUWQw6pZHmO7Tgslkvc7RZN1xCui6qqOEJQliVZllEUBWEYju8Bl8uFP3E+n1E8V+BYKzYrgyrPsIwFdZGPvK/Lp48DDocDdV2PYmVVEScJfhCw9T2iOKZpGpTQsVjPpyymN8RijTmbEtkmxu0XUneNH0ZYlsXGtlmZJoEUGAQHYdfbUu12NG1L+zuUSnYKowjP98dQdZ1C2hrsPuz3f1nqupbT6UTf97QyPx6PY32odV0nJ3QdhKFjqt9IPMFyfksWepjajCoJuM9yhHDxpa1MruQ5KL5lcHfzEXXyAUdX+T65wtbmzK7e40gupLUkiUnTSu6wH84xWv5fKNruB6+9iBcbweQ+55VpS854aW64Lmrahx1VvZe7+0rXx08X/teVxwlXjw1v3IC3fsQnKfTOC/ic5iNfpwWnx5/UsmlV3UnB5FnBX7GQV3rAFYCnAAAAAElFTkSuQmCC'); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"context vector","title":"context vector","src":"/static/d9f826e1dae94728bc94f201b82cd0ff/5b692/context-vector.png","srcSet":["/static/d9f826e1dae94728bc94f201b82cd0ff/733ef/context-vector.png 320w","/static/d9f826e1dae94728bc94f201b82cd0ff/70d1f/context-vector.png 640w","/static/d9f826e1dae94728bc94f201b82cd0ff/5b692/context-vector.png 968w"],"sizes":["(max-width:","968px)","100vw,","968px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 5: Context vector calculation for "},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"t=1"}]},{"type":"text","value":", "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Now a lot of things happen (3 steps in the diagram above). First, we multiplied every attention weight by corresponding hidden state ("},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"×"}]},{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"a_{1,1} \\times h_{1,1}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.8694379999999999em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2222222222222222em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mbin"]},"children":[{"type":"text","value":"×"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2222222222222222em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.980548em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]}]}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"×"}]},{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"a_{1,2} \\times h_{1,2}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.8694379999999999em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2222222222222222em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mbin"]},"children":[{"type":"text","value":"×"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2222222222222222em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.980548em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":"…). Then, all of the results are summed to use as a "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"context vector "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"c_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Note:"}]},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nYou’ve probably noticed that at this point “context vector” is actually a “context scalar” but this is just because we decided to have only 1D output (easier to show and understand for now). I’m going to switch to vectors when we get to abstracting attention to its own layer."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"4-compute-first-output"},"children":[{"type":"element","tagName":"a","properties":{"href":"#4-compute-first-output","ariaLabel":"4 compute first output permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"4. Compute first output"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 778px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 63.49614395886889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACm0lEQVQ4y22TWW/TUBCF87OReOYH8IKEELyAWAUICSFQoWzpQps2SeNA0qTeYsdbaju2EzeJk49xUqoidaTRvfbonnvOzLmVTucPpmmy/2sf13U5OqqhtBUMw6Ba/bmu2baNZVnrLPdlrdyXsVqt1vkvKuXhMAypCdB8PqeltDAHA9I0XV9SFEtuCs/zpFZcgV4Bnh5WsTQVo3mApWvYvd/oyjHu0Ear75OcB0RxTDAaEcvqyxpG0Zrhcrm5bHmNZeVg+yND0+BkZxtbVrPbprVfZeR7NH9+IQ48dJHYUhR6p6c0Wi1UTaMtyhaLxX+sS9CKZg5whb7jB9QbDTq9Prr8830f2/UYJ8mNkkfC9B+gEweMsmjDsFs/xLUt9N9NdPUMs9+l324KQx9VqZNGIeE1yefhOdM8XwOWPV+yojFp486CDeDnl4/Re11+vH2GMzBp7X7n6OsnAtdh+9UTsjDAGjqciFRNpHZFtivMS/AszSg799R8w9lE3wAey3Q7nQ471Sqm9Gpvb49GvU6/3+fz1ha2NL90QSRZrkEQXPWrZFmGJQon0+kG8I4TsnWicFu1qEnv7h6f8MCP2G02uXU2YHfo4ssBW1j2xAG9/gv8oEMUJfLdw9BVPP8Ds/nGl5X7csiZLbjXM3CnOdt+yGvTIRGP3ZOamk0Qw8kACiaTRLJJnvss5gVpljEQex0evmCaORvARFNKASRaCxYXrBKfxOyui6n8K6Y3T7mMizShXd1hKAM8DTRBEdskBw8pxjbjXw8oUo9c/ca0857VLCWrPaKIzcueLS/NK8cuDZ1Ln6ePn2Mkfd4lW+RFTmViKayEWWY2WS5mpGabsVrnYhwQ//nBxNP/e7PX326RyyBGIYPYZtepYcQOfwEk7MRp8opVIQAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"first output","title":"first output","src":"/static/3eb1c3d89a6d2ecfb8b664bd06567aba/4fa3d/first-output.png","srcSet":["/static/3eb1c3d89a6d2ecfb8b664bd06567aba/733ef/first-output.png 320w","/static/3eb1c3d89a6d2ecfb8b664bd06567aba/70d1f/first-output.png 640w","/static/3eb1c3d89a6d2ecfb8b664bd06567aba/4fa3d/first-output.png 778w"],"sizes":["(max-width:","778px)","100vw,","778px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 6: Decoder's output for "},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"t=1"}]},{"type":"text","value":", "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"At the end of the first timestep, we can finally compute the first output from the decoder. That output is computed using context vector "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"c_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", previous decoder’s state "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", and start token "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"y"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"y_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.625em;vertical-align:-0.19444em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.03588em;"},"children":[{"type":"text","value":"y"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":". Interesting thing is that in that whole process we don’t have to train "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"f"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"f_{att}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.8888799999999999em;vertical-align:-0.19444em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.10764em;"},"children":[{"type":"text","value":"f"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.2805559999999999em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" as a separate model. The "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"whole process is differentiable"}]},{"type":"text","value":", so we can just backpropagate through the computational graph."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"5-and-repeat"},"children":[{"type":"element","tagName":"a","properties":{"href":"#5-and-repeat","ariaLabel":"5 and repeat permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"5. And repeat…"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 850px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 60.11764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAACaUlEQVQoz2WS2WvbYBDE/f+/FgqFQGkf00D7kJY2DYGkTtI4p235UKRIsizrtGRblyUf+fWTQhJoFpYVn2B2dmYaQRAg38vIssxd+w7btmk2m0wmT3M0GuG6bv1eteM4mKZJHMdU9fj4WPdzNTRNQ1Xusawx5sggTRL6PYlETKnbYbVa8X8VRUEURW8Aq9kwlSHS6RFav4NydYrv2nSPf2GbBvLFCaFlYFoTpF4PVVXpDQcYFWvB9AmFF7CaoSOYDTp36A8KSl8SLEe0ry6YWFb9PpsGLAWj6sSKddWe5zEV71UtVwXlevXKMAzDepvj2HhCq6HQ0tD1+tu2J+R5/ubk5XL5ouEk9XCz6SugNuhy8XsfpXvL3fEBoe/R3N/Dty0uD7/jGiqO59OVJHRdQxPLotmMLMtqkOPkHHmpvgJa+gPnhwdIt9eciTns9zn4useDMOrk53d6tzd4vl+zHo8t4bCNYRhUZs4E8Jl0ySTyXgFvZws+B3OORuN6ysKA927I0A/4oI+5THM2aUKWlwSBSpy08MUVVZTiRYJrN0USrNqcx+2WxiBd8mnk8Nfx2VFMnDjhnWygRzN2ZI1WtKBYzJkvUmGGSpK2a72rTC6ynKubb8I49cXwxjqZkpuSUHpOanTqH6l2DZuSfNyDLHybw7IkFaaUusFEpKI/1ylDn7UxorHyZdLOHiu3R9LeZSuA49ZH1rFH1vlCYd08bd9u2IqTqsoql6OQ7Y8DImvI/voUr9VksbtHY1NklEnEpsgp0znbVUlsPVDEEZlnkAUWzwl+Dm/lcGWK77gousKfwQXtXpup0P0fnrx6rgHrNDQAAAAASUVORK5CYII='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"t 2","title":"t 2","src":"/static/ea7bae6af4a2ce44430365d4f20301f6/861bd/t%3D2.png","srcSet":["/static/ea7bae6af4a2ce44430365d4f20301f6/733ef/t%3D2.png 320w","/static/ea7bae6af4a2ce44430365d4f20301f6/70d1f/t%3D2.png 640w","/static/ea7bae6af4a2ce44430365d4f20301f6/861bd/t%3D2.png 850w"],"sizes":["(max-width:","850px)","100vw,","850px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 7: New context vector for "},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"t=2"}]},{"type":"text","value":", "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"At the timestep "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"t=2"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.61508em;vertical-align:0em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2777777777777778em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mrel"]},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2777777777777778em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.64444em;vertical-align:0em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"2"}]}]}]}]},{"type":"text","value":" only thing we have to do is to "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"change the input to calculate the alignment scores from "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" to "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]}]},{"type":"text","value":". Using the same process we compute new scores ("},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"e_{2,1}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"e_{2,1}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":"…) and attention weights ("},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"a_{2,1}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"a_{2,1}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":"…). Then multiply new attention weights and encoder’s hidden states to compute the new context vector "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"c_2"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":". At this point, the whole process just runs in the loop until the decoder produces "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"[STOP]"}]},{"type":"text","value":" token (sometimes called "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"[EOS]"}]},{"type":"text","value":" token, eng. End Of Sentence)."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"attention-weights-visualization"},"children":[{"type":"element","tagName":"a","properties":{"href":"#attention-weights-visualization","ariaLabel":"attention weights visualization permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"Attention weights visualization"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 717px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 105.02092050209204%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAAC70lEQVQ4y3VUyUprQRC9xiGKUzZGcCGCcQBBQXEWXKkBN0mWCrpyk09w5Q+4ceUixnnAqFtFRPwEd4obFaPRJIoDTnE4j1Pvdefe5L4LRfftrj5ddepUG/j3/f7+ivH7+fnB6+urXrfzMY9mH8PO+evrC+fn5xo8Ho8jGo3i+/tbr9GXY+Z5I/M2BXh6eqoPn52d4eTkBM/Pz7J2c3OD9/d3JBIJmfOil5cX3N7ewsgE+/z8lIjoyDWm/vj4iGQyievrazw9PeHq6gqpVEpAefHHx4ecFcBMnnjrwcEBQqEQFhYWMDc3h3A4LDY/P4+lpSVsbGyILS4uYnl5GVtbW2I8pyPkjZwfHh7C7/djeHgYhmHYWlFREQoKCrLW29vb04CxWAz39/cSUU1NDTY3N9HU1CSODocDeXl5KCwshNPpFDD+K8vNzRW//v5+a8osRiQSkc3q6moEg0E0NjYKSH5+PkpLS1FeXi7AvITAXFcRDgwM/I2QRjB+6+vr2sHlcmFychJutxtlZWXwer2oqqqSvZycHO2n5j09PWkdEvDh4UHIVmlyLC4ulijoPDs7i7a2Nsu+ed7d3Q2Dcri8vMTFxQXu7u50hOYDHR0dwm1fX59tkSyALARFe3x8LDqjDMxO5Ovo6AhDQ0NZKdoCshOY7tvbm6S+vb0tm6pydO7t7RU++T82NgafzycFygS0cKiqvbq6mpWy+X90dBRTU1NoaWnR0VoAlWTYRtTi2tqabJaUlGSlyJEFIs/j4+M6E7UvKZs7hQ2+srKiucskX9EwODgocurq6rL4khqtQ3JJUCUbO51xpMg5ZxfNzMxgZGRE+1lS5itD+fBBsOPQbOoCthofi0AgIP8iKwXIN422s7Mjm+RK8UPjXLUfrbKyUvwop+npaQmgs7MzDaie/N3d3f9GxkPsZVpFRYWYKiCjnZiYSANS4OyU/f191NbWoqGhAXV1dWL19fV6pHk8Hhmbm5vR2toqfFJOe3t7+AMe7dGqDQAo+gAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"attention weights heatmap","title":"attention weights heatmap","src":"/static/fffc70b061aee6d776d625efda7e885f/6f2d1/attention-weights-heatmap.png","srcSet":["/static/fffc70b061aee6d776d625efda7e885f/733ef/attention-weights-heatmap.png 320w","/static/fffc70b061aee6d776d625efda7e885f/70d1f/attention-weights-heatmap.png 640w","/static/fffc70b061aee6d776d625efda7e885f/6f2d1/attention-weights-heatmap.png 717w"],"sizes":["(max-width:","717px)","100vw,","717px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 8: Attention weights for English to French translation, Source:  "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://arxiv.org/abs/1409.0473"},"children":[{"type":"text","value":"Neural Machine Translation by Jointly Learning to Align and Translate"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In the original paper, there is a simple visualization of the attention weights "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"j"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"a_{i,j}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.311664em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.05724em;"},"children":[{"type":"text","value":"j"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" generated when translating the English sentence "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“The agreement on the European Economic Area was signed in August 1992.”"}]},{"type":"text","value":" into French "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“L’accord sur la zone économique européenne a été signé en août 1992.”"}]},{"type":"text","value":". This visualization shows us a couple of interesting things."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The first thing is a diagonal pattern which tells us that model put more attention to corresponding French word from the same position. The second thing is more interesting and it is the phrase "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“European Economic Area”"}]},{"type":"text","value":" which in French has reverse order "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“la zone économique européenne”"}]},{"type":"text","value":". We can see that when generating "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"la"}]},{"type":"text","value":" token model puts more attention on "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"the"}]},{"type":"text","value":" and "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"Area"}]},{"type":"text","value":", then when generating the "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"zone"}]},{"type":"text","value":" token it attends to "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"Area"}]},{"type":"text","value":" and "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"Economic"}]},{"type":"text","value":" (ignoring "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"European"}]},{"type":"text","value":"). Another interesting observation is "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“a été signé”"}]},{"type":"text","value":" where when generating "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"text","value":" and "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"été"}]},{"type":"text","value":" tokens, the model attends to both "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"was"}]},{"type":"text","value":" and "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"signed"}]},{"type":"text","value":" (it makes sense in French because we need to know an exact variation of the word "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"étre"}]},{"type":"text","value":")."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This heatmap is important because we didn’t tell the model which words it should attend to, it learned this by itself. Additionally, we’ve got a kind of interpretability of the model’s decision."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"attention-doesnt-know-that-input-is-a-sequence"},"children":[{"type":"element","tagName":"a","properties":{"href":"#attention-doesnt-know-that-input-is-a-sequence","ariaLabel":"attention doesnt know that input is a sequence permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"Attention doesn’t know that input is a sequence"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"You probably started to worry about what happened with my information from the last step:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“We’re not using the fact that h vector is an ordered sequence. It is used as unordered set instead. To solve this we have to add a positional encoding to each element”"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I’ve written a piece on positional encoding as a separate article because there is too much information to squeze into this one. If you’re interested please check "},{"type":"element","tagName":"a","properties":{"href":"https://erdem.pl/2021/05/understanding-positional-encoding-in-transformers"},"children":[{"type":"text","value":"Understanding Positional Encoding in Transformers"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This is still a thing but instead of solving that problem, make use of it to abstract attention mechanism and use it for something different than a sequence of text. What about describing images with attention? There is a paper from the same year called "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1502.03044"},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”"}]}]},{"type":"text","value":" that uses attention on CNN’s embedding to generate image captioning with the help of an RNN decoder."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"div","properties":{"className":["center-all"],"id":"rnn-imtos-with-attention-diagram"},"children":[{"type":"text","value":"\n        "},{"type":"element","tagName":"image-with-attention","properties":{},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 9: Image Captioning with Attention (still RNN), Designed base on "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1502.03044","target":"_blank"},"children":[{"type":"element","tagName":"i","properties":{},"children":[{"type":"text","value":"“Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”"}]},{"type":"text","value":", ICML 2015"}]},{"type":"text","value":" Paper"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In this paper, the authors are proposing a solution based on convolutional feature extraction instead of the standard RNN encoder network. We’re using those features from CNN to compute state and then to compute alignment scores for every timestep of the RNN decoder. As in the previous example, I’m going to walk you through the whole process, but you probably are able to understand it base on the interactive diagram above :)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 637px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 67.66091051805337%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAAC00lEQVQ4y4WS2W/TaBTF86/xwL/AA/AwgJAKFHgBKsTbSCAQEjMtm0olUIFhhkoUqQ10gaY0BSpoKV2y0DUlSx3HjRNncWzHzo9rl0UZJPiko3vt735H595zQ61Wi9/BP27TwSzrmEaJRqW8GwWu2wzuv9WF+N35WlhSFWITw8Qiz4i/GmHh5TCfpsepCWkbYbPZxLIsTNP8jnq9vhsFjUYDx3UpFxQSkWGSr56zEh0lHgmzOj1GTVS3EfoP/Q9FUXg/O8tyLEY8kWBjc1NiMiD2Swu5NEsvh1gWlUsTz1h4MURMyH8i9BUUCiqZbJa1jU1WVlfJZDKsb2wE/7a2ttDLBrqSIzkZJiEka29eSOvhIJoyz2+EPkKO4wQtfm/zf7FardKwbYpKlg8jT5gfe8rM8ABzI4N8kFzX1HbCX/vxw2XPsbF0jZqW5/3UJF61TH5zjbiMKLj3vN2WWy0Pp2njyIMgfs09z20jd4TXb06X+CmvYkjuI5VOUy79cDpUr1V5Oz3F6+lJolMTzMy8JhqNoBc12TGPol8sm5A0LU5mNbryJbq2i5wRnJdcabrkMzmKemVXYbm4w0BfH3euXKH30mUe3LzJwxvXUTNpFFEyFA6jiUkr0tEf2yU6tSqnBMdUg05BzpELzxQDl4XOEsIdjX96url14QKD3bd51NPD/b+uEZufY3RsjHv9/SzNzfF0YYlDn1VO5Ip0ZnfoELWdgnepHMsfw2zn+8TEJCFD1xns66W76xzXz55joPc2dy9fQv2cYnV9nX8fP0bZSrFYMzmslDipVThdqHBc1J0qGKQbLlY1S8l4i22rhJTtHBd7/ubIwf3s27OXPx/9x9XxCbK5bLA28WQSu2KQsJscSCl0COkxUXhUlHZkNDK202ZeyCiXiMzPMjo+Sv/de8wsLrBoVKg47YVFGX6k1iBat4nWLKbqluQWVdffBn+9vMDlLzr79fJyuipDAAAAAElFTkSuQmCC'); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"cnn alignment","title":"cnn alignment","src":"/static/7ff8d4eda4962bdfba3a56aa4018896d/c4799/cnn-alignment.png","srcSet":["/static/7ff8d4eda4962bdfba3a56aa4018896d/733ef/cnn-alignment.png 320w","/static/7ff8d4eda4962bdfba3a56aa4018896d/c4799/cnn-alignment.png 637w"],"sizes":["(max-width:","637px)","100vw,","637px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 10: Alignment score calculation from extracted features, "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We’re assuming that CNN is already trained and produces our 3x3 grid. We’re going to use that initial grid to predict the initial hidden state "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" (sometimes it could be randomly generated or even set to 0). Now we have to pass the same grid and "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" to the alignment function to calculate corresponding alignment score for each value of the grid "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"j"}]}]}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"f"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]}]}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"−"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"j"}]}]}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":")"}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"e_{t,i,j} = f_{att}(s_{t-1}, h_{i,j})"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.311664em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.05724em;"},"children":[{"type":"text","value":"j"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2777777777777778em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mrel"]},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2777777777777778em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:1.036108em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.10764em;"},"children":[{"type":"text","value":"f"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.2805559999999999em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mopen"]},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.301108em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mbin","mtight"]},"children":[{"type":"text","value":"−"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.208331em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mpunct"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.16666666666666666em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.311664em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.05724em;"},"children":[{"type":"text","value":"j"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mclose"]},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"text","value":". That gives us alignment scores for "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"t=1"}]},{"type":"text","value":" timestep. As in the previous example, each alignment score is a scalar which tells us “how important is given feature in the current timestep”."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1080px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 39.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABkElEQVQoz42Qy27TUBRF/atMGLUS7U8wKUVkyoAJc1okHlKhtANAIuGhOEnjJErixI7TmGs7ceJXYi+OTcsAkOBIV9u2vNfd+2j8Nts0ZdZrMe18Y2a0qvckjnH6bSz5Zhs6WZqQZRlhGLLZbFiJJvJfnudoyvNwXRelFJEY43XI1eVrmmcnoq+Y21MG/R6di5e03jyn/e4FUbgkTTPMyYSxaVYaJwmx+LXReMxwNKLU+fWCwFO0BdQUc0fAc9uibxi0BKSfnVbA9TKo2iQCWUiYMlk5URSh/aq63ZJKjVRuWQ4Nhp/eYzUbBJJ8t8twBldYXR271yYT0G6XS8q0gpb1S39V2ZyMmUxNoW9+3lrAZZpzopa8jTIs5ckec/53tCdHD3hae4T+pcHneh19bLLv+NyxFXtOwCBQqMVX8iKjKAo5+Y3+/WhH9w54fHxM4+MHLs7PaXQNDh2Pu/Z3DgTYdWeEfl2AaZXg1nj7/EfCw/09as9OMVchshR82UfNX3PfXfFQhfg3nrzS4p+VfwD7ZlK2CVLchgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"cnn attention weights","title":"cnn attention weights","src":"/static/b2041c2d11e89a9c2e5a2913684fdfbc/9d22c/cnn-attention-weights.png","srcSet":["/static/b2041c2d11e89a9c2e5a2913684fdfbc/733ef/cnn-attention-weights.png 320w","/static/b2041c2d11e89a9c2e5a2913684fdfbc/70d1f/cnn-attention-weights.png 640w","/static/b2041c2d11e89a9c2e5a2913684fdfbc/9d22c/cnn-attention-weights.png 1080w"],"sizes":["(max-width:","1080px)","100vw,","1080px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 11: Attention weights, "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"With alignment scores calculated we need to apply softmax to normalize scores to some probability distribution that sums to one."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1082px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 47.134935304990755%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAAB3UlEQVQoz5WRy27TUBRF/amMCl+AxJAfaMsAMWBSEAMGKAHKpCGtKhpBE5I274Tmbefl2LEdx/EjibO4NiUSgglH2rK05bvuPvtK/GPWvsesd4faaaLLXcJwh+fYaPeeMRqw2+1Yr9d4nrdXGIZIm80Gy7KYz+fx1w8CloZO7fyU8lmSH5nP6LpOu1GNvdJZgtb1JVtxzjBNur0e/cEAZTjE930kU5jtToe7Votev89kqqJPJ1QuPlFMvacugKPRiFrxhmr6owAmY6Af+IQipW3bWIvFr81EYimKuV9VGIHQeuWg1UvI+a+MKze4rkvgLpGF1y7m0AddLG/BxFbjVJGis9G2kjZTReSuiCzjie6iWQqlVwGn5pIrN2Cmz0VnEF1tO078T8uXydnVv/qX0skEr4+OePviOc1qmUI2S2Gi8mhq8mA058lsiblUWVj1OEnU9W4L+qKNot3GkOiBfktKvDrh6cFDXh4f8/36GxepFFftLgdjIwY+Hlv0hw2MeZ6BLNNsCPBmR6OVRRsX74Eh8QpRwvPMF54dHvIhl0cXXYWibG2z5Y1Y98SweSdk2Q4rx0NRFJTxmK14db1UpmK2cLfuPmUM5D8mEB33BFSr1nBuC2RsEcI3/gD+BPq1mawpreqvAAAAAElFTkSuQmCC'); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"cnn attention mask","title":"cnn attention mask","src":"/static/1a4c792fa2776dca76fd230ac853bec9/2fd86/cnn-attention-mask.png","srcSet":["/static/1a4c792fa2776dca76fd230ac853bec9/733ef/cnn-attention-mask.png 320w","/static/1a4c792fa2776dca76fd230ac853bec9/70d1f/cnn-attention-mask.png 640w","/static/1a4c792fa2776dca76fd230ac853bec9/2fd86/cnn-attention-mask.png 1082w"],"sizes":["(max-width:","1082px)","100vw,","1082px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 12: Compute context vector and generate first output, "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Now all we have to do is to compute "},{"type":"element","tagName":"a","properties":{"href":"https://en.wikipedia.org/wiki/Hadamard_product_(matrices)"},"children":[{"type":"text","value":"Hadamard product"}]},{"type":"text","value":" (element-wise multiplication, "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"j"}]}]}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"×"}]},{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"j"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"h_{i,j} \\times a_{t,i,j}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.980548em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"h"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.311664em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.05724em;"},"children":[{"type":"text","value":"j"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2222222222222222em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mbin"]},"children":[{"type":"text","value":"×"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2222222222222222em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"a"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.311664em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"t"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.05724em;"},"children":[{"type":"text","value":"j"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" …) and sum everything to get a context vector "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"c_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":". The rest works exactly like in the previous example so we use context vector "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"c_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", start token "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"y"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"y_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.625em;vertical-align:-0.19444em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.03588em;"},"children":[{"type":"text","value":"y"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", and initial decoder state "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"0"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"0"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" and pass it through "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"g"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"U"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"g_U"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.625em;vertical-align:-0.19444em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.03588em;"},"children":[{"type":"text","value":"g"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.32833099999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.10903em;"},"children":[{"type":"text","value":"U"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" function to calculate "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" state and achieve some output token "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"y"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"y_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.625em;vertical-align:-0.19444em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.03588em;"},"children":[{"type":"text","value":"y"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Note"}]},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nThe sum is not required at this point, I’m just doing it to have the same shape of the context vector as in the previous example. We could easily use a 3x3 matrix as an input to the "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"g"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"U"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"g_U"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.625em;vertical-align:-0.19444em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"],"style":"margin-right:0.03588em;"},"children":[{"type":"text","value":"g"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.32833099999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.10903em;"},"children":[{"type":"text","value":"U"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" function."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1080px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 48.05555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACMElEQVQoz12Sy3PSYBTF+VvVce04XXTjUqcbF260486FKxetdrRTWstUrfhqC7ZAG6CQQMkD8iKBBEj4eZPOME4zuXPyncl9fecUuPMkizl6s06vdpZHHAYkaYrRvszP2sUpoTsiXS4JgoAwDBlnOJmwWCwoOI6DbdtkOI0i4ukE5fiA8/331A53MLQOvf4NDeEuDj7wd2+LUa9DKs0Nw6DTVemoal5jNptRaLZaKM0mLUFNEl3Hpv61SKW4nUf/ukm706Va2qVa3OL00zsstZ1vs5TJTdNiMpnm50gGKixldHlJkoT5fM5MSKfdQCkfoZ+foGtd4lmM1ZXClV90hZt4NoPQxA09pvEUI7DydfOVraGJaRmSFOVdslXOZgnFoUtZ0JDugR8SCA50PZ8mWaZ8tsuMEo9wOWXf+S5ckucX3rx4wdvNV9QqZ1QrFS41jXXD5d6Nzf2Bw6k3Jok0uXQXXTcwpGgWlesS7sTC9kya1g8RbnFb8Pmjx7ze2ODk+BvFvT1O6g3WTY8HustD06dsjhjbJZlQR1HauXi+KNpSPhKNDW4MFbW7u3JJ4cnaGi+3d1AzlX0fL4rZdEOemi7Phj4Xjkvg+NiCV8oVqQgRD3SuRaxBNCSxRiiNmnybtwXn4ruF/LT8z4tZUuazNBcsizTnVU2V+zZJj47Run/4klSZ7Jfo139yGP8WYUWUVZVV8vKu11dcHEe59zzbYTAcoOht+r0efuCJ6qJ0mvAPPmThv052b8oAAAAASUVORK5CYII='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"cnn second timestep","title":"cnn second timestep","src":"/static/d0e833aab2689ef7be2fed2deaa0c538/9d22c/cnn-second-timestep.png","srcSet":["/static/d0e833aab2689ef7be2fed2deaa0c538/733ef/cnn-second-timestep.png 320w","/static/d0e833aab2689ef7be2fed2deaa0c538/70d1f/cnn-second-timestep.png 640w","/static/d0e833aab2689ef7be2fed2deaa0c538/9d22c/cnn-second-timestep.png 1080w"],"sizes":["(max-width:","1080px)","100vw,","1080px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 14: Second timestep ("},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"t=2"}]},{"type":"text","value":"), "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://erdem.pl/2021/04/introduction-to-attention-mechanism"},"children":[{"type":"text","value":"Source: erdem.pl"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The same as before, we’re using newly generated "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"s_1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"s"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":" state to compute new alignment scores "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"mo","properties":{"separator":"true"},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"j"}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"e_{2,i,j}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.716668em;vertical-align:-0.286108em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"e"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.311664em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"]},"children":[{"type":"text","value":"i"}]},{"type":"element","tagName":"span","properties":{"className":["mpunct","mtight"]},"children":[{"type":"text","value":","}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault","mtight"],"style":"margin-right:0.05724em;"},"children":[{"type":"text","value":"j"}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.286108em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":", which then are normalized with softmax and computed into context vector "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"msub","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"2"}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"c_2"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.58056em;vertical-align:-0.15em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathdefault"]},"children":[{"type":"text","value":"c"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.30110799999999993em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"2"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.15em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]}]}]}]}]},{"type":"text","value":". The process stops when the decoder produces "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"[STOP]"}]},{"type":"text","value":" token as an output."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"visualization-of-the-attention-weights"},"children":[{"type":"element","tagName":"a","properties":{"href":"#visualization-of-the-attention-weights","ariaLabel":"visualization of the attention weights permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"Visualization of the attention weights"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The same as in sequence to sequence translation we are able to visualize attention weights in this case. I’m going to use one of the examples provided by the authors."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 963px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 63.966770508826585%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAADW0lEQVQ4y22Ta0ybVRjH369+cR9IyJzZ1JjFjGjcEBUXCQ7YzIQqc2s3lIvpxm1jS5kBpxDIiJgAFpBKEbbiYNlcB1gKLWVlwLZ2IBS6TS4tlwECMS4CmnjjUvj5choTP+wk58P7zy/nPc/veY40MtuPpc9Io7OODreZzeX1jqItL6ayRkdldQVz87P4fD4u1dfK3zqKtF/Q2uZn7/Y4qNCXU23QY2y6ilR2IZOolGDC1C+RUhQrIFNzA0/tCGDX7p08GfgEnd0dbGxsUH2hgoQTHyBJEgnqY4Jts5lJPBFHwLYtBO3ZiVRgPMd5UzJXnGcwNJ3z/7XPQaQinJjDEeTka5idmxG5Z2aYrLzTJCUfpn/QKbLf/lygwXqVqOhQjqfEIV1xldF4L48b7gIsLeUC6nZ0EvHOXsIigikqzmdl+R+WV5Yp0RUS/f4+irV5zM9NCfb+yACF2lwyNB9Ra6hEcg/9gMNl5+7ATdzDvQKa+WmaRtN1zJbvMVtNLC4tCIebpbe1t2LvtOEd9wh2YnIci1y2zW6Rb92L9O2lGt47omDrjkBeDwvxN2VsBHVKPMGhLxPw9Bb5oJsi11V+yZuRb/B80DOc0qSKzDXQQ9TBcJ59YTuh4SFIc4+mqamv5IAiTHbjF/3HX79jv23lZKaasMgQBgb7RN5g/g71yXjZbZTsNstf8tAgH+ecQZOdKjdKidR+x0JhaQ6nzyZRUnxeQFNzk+jrylCnK/kw/l3GvB5W11ZJlj0dijtA5NuvUvh5nmD1Bh0xqkjUaUdQKqORvOMjuNw9DNzrZWT0RwEtLP5Kr8she2mh65adpaVFfOs+bjk7MbVc51rDZQbd/X49E6OyQxNNzdfkEWpFqpUdxioVHEtU8Vn+JwL65dHPdN2xMzT2gPueQbnDf+NbW6NKHvSMs+lUGb7G+3CUxy0p+9NMtj0XiCohlkNHo0XYbrey57UXycrVyH4ymJ2fZnV1hd2vBLFfsY+vvimhy3FDsJvd//+WMrLSURzdT0OzAX2VVkC3e7rZvmurLP8tVHEH8XiGRX4qOw1VYgxFpbkYjfUiW19fF6/ovy1Z7c2YbUbcD5zYbM3+2ZoaQ3+xlFJ5kFPTkng4OSFyZ38XF+t05Bdk09HR9tgD/wXqrgLmfFd1WgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"show attend soft example","title":"show attend soft example","src":"/static/8872ff9181c036664ce5831cb2949278/b1718/show-attend-soft-example.png","srcSet":["/static/8872ff9181c036664ce5831cb2949278/733ef/show-attend-soft-example.png 320w","/static/8872ff9181c036664ce5831cb2949278/70d1f/show-attend-soft-example.png 640w","/static/8872ff9181c036664ce5831cb2949278/b1718/show-attend-soft-example.png 963w"],"sizes":["(max-width:","963px)","100vw,","963px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 15: Image attention visualization, white regions have higher value of the attention weight, Source:  "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://arxiv.org/abs/1502.03044"},"children":[{"type":"text","value":"Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"As you can see this is not an ideal solution for explaining a model but still could give you a kind of intuition about what is happening. Especially when we look at the tokens like "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"frisbee"}]},{"type":"text","value":" or "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"park"}]},{"type":"text","value":" when the model attends to those exact objects. In the case of the token "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"woman"}]},{"type":"text","value":", both people on the image save similar attention weights but that’s still ok because the model could decide which one is the subject and how to name that person."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"There is one more type of attention called "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"hard attention"}]},{"type":"text","value":" where instead of using the softmax function, we’re selecting a feature with the highest alignment score and using that feature’s value as a context. It requires some changes in the training process which I’m not going to discuss right now. Here is an example of hard attention."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"figure","properties":{},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 974px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 65.91375770020534%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAADk0lEQVQ4yyWSaVNTZwCF7+/otNXWYgvIYlJMIGERwyIE2QVboQWtTiMMsi9CqEhZalutSGaINYhAQwCRTRRZau0gQthmkOl0E2tlqR212g+EJPD0cntn3i93znvmPec8woPFezQPGzAOfE3TUD0bOJmdnaaiSk/Vl5WUf17K4qOHvHz5D5U1p6kW/5WdKWH0h2G2PuO3Bs7UfCbpmlpNCJfNFYQdlxN+QklSaZAosdPebsbF7U12Kz14y/V17lvvsby8hJvnDrwVHmzb+RrnLp6VDGPi9uPq7cIOt20cPpKEcP5GDYVtqXRYc6k369jctHOtpwOZ2pOohL2ERqqYm5tmeXUJeYA34TGBaPYruXL1kmSYmBpPQNgeQrW+FBZnIXTNXaJlooiRhSo6LBWiZJP+wV4i4oJJPRpP7RflPP7jEUsrT9AmaEhK0VKqz2Z87C52hx1dzidEJ4aQlXuE7i4Lwi+LC4zPjjI+M8rE3F3RboM/nzzm9shNRu7cZmj0Fs+eP2NtbY2R74cYvjPI4MgAvz38VUyzydj4j5J260zPWRFOlRUgU3ihDFCgiQjCtm6jr+86crG/gBA1cj9PpmYmefp0leAQFYGhaqnHhssGKfJHacn4BvmIOm90J48hdPa0ERIVJAoVRMTuw2Zbo/9mL8cy09HGa1D4ezI9a2VldVm85IVGG4DM1w2D8YJkmHQ4HtW+PSgDvTiekYZwtq4axV5PAkO80Wj8sK3Z6OyxoIn2JzzaD5nchanJCanDXcqd4qtlJH8YSW93Jw6ng+hDkcjVrkSLA35zvhZhK7vpagOtbY20WZpxOp389PMCRlM95vYmGpuMrKws8+rfVzQ2G2kxmxi41c3i4u84N5x091/jSouR670W5udnEdo7zRScyqVYX8Dpaj12u52p6Unyik5SUl5EXkm2NMCLF88pLsunrKKEzLwT3BjslyLXGc5RpM8nuzCLiw0XEHLzM3Fx384u+Xv4qL2kUSzt36H0l6EKVojAvsGEdVwC29XjbQn27e+KYNf9D/aB2HAJ7HfcRbDTRbAL9Hn4iIVq4wJJ+Tge+/o6li4zaRkppOsOolC5MzNjlcDeLQ4UttVtlJqW1kaJ2YTUWPxD3xf7Vol85iN8VVdLwgeRZOakYzIZcDgcEmcxyeEc/fQQB5OiWHgwz19/r5KYckCEPYGKyiIm7o9JYOcUZ4iwR5FfrKO/r4v/AHsArqV0+OAnAAAAAElFTkSuQmCC'); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"show attend hard example","title":"show attend hard example","src":"/static/89ddc733bf475797151dd73913b6e131/f6062/show-attend-hard-example.png","srcSet":["/static/89ddc733bf475797151dd73913b6e131/733ef/show-attend-hard-example.png 320w","/static/89ddc733bf475797151dd73913b6e131/70d1f/show-attend-hard-example.png 640w","/static/89ddc733bf475797151dd73913b6e131/f6062/show-attend-hard-example.png 974w"],"sizes":["(max-width:","974px)","100vw,","974px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"figcaption","properties":{},"children":[{"type":"text","value":"Figure 16: Hard attention visualization, white regions are the regions which model attends to, Source:  "},{"type":"element","tagName":"a","properties":{"target":"_blank","href":"https://arxiv.org/abs/1502.03044"},"children":[{"type":"text","value":"Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention"}]},{"type":"text","value":" "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"As you can see, the caption has changed. Now it’s saying "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“A man and a woman playing frisbee in a field.”"}]},{"type":"text","value":" instead "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“A woman is throwing a frisbee in a park.”"}]},{"type":"text","value":". Attention regions are not fully related to the generated token (as in soft attention), when generating token "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"frisbee"}]},{"type":"text","value":" model attends to the child."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"lets-abstract-the-attention"},"children":[{"type":"element","tagName":"a","properties":{"href":"#lets-abstract-the-attention","ariaLabel":"lets abstract the attention permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"Let’s abstract the Attention"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Now, when you know what the Attention is, we can start working on abstracting the idea to create so called "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"“Attention Layer”"}]},{"type":"text","value":". "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"references"},"children":[{"type":"element","tagName":"a","properties":{"href":"#references","ariaLabel":"references permalink","className":["anchor"]},"children":[{"type":"element","tagName":"svg","properties":{"ariaHidden":"true","focusable":"false","height":"16","version":"1.1","viewBox":"0 0 16 16","width":"16"},"children":[{"type":"element","tagName":"path","properties":{"fillRule":"evenodd","d":"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},"children":[]}]}]},{"type":"text","value":"References:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Sutskever et al, “Sequence to sequence learning with neural networks”, NeurIPS 2014 "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1409.3215"},"children":[{"type":"text","value":"https://arxiv.org/abs/1409.3215"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Bahdanau et al, “Neural machine transla$on by jointly learning to align and translate”, ICLR 2015 "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1409.0473"},"children":[{"type":"text","value":"https://arxiv.org/abs/1409.0473"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Xu et al, “Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”, ICML 2015 "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1502.03044"},"children":[{"type":"text","value":"https://arxiv.org/abs/1502.03044"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"style","properties":{"className":["grvsc-styles"]},"children":[{"type":"text","value":"\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n"}]}],"data":{"quirksMode":false}}}},"pageContext":{"slug":"/2021/05/introduction-to-attention-mechanism"}}}